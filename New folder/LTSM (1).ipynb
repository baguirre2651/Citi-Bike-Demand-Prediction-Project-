{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e81eacf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.formula.api as smf\n",
    "import matplotlib.pyplot as plt\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.metrics import mean_absolute_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddd5aafa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e470a0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0          1  2011-01-01       1   0     1        0        6           0   \n",
       "1          2  2011-01-02       1   0     1        0        0           0   \n",
       "2          3  2011-01-03       1   0     1        0        1           1   \n",
       "3          4  2011-01-04       1   0     1        0        2           1   \n",
       "4          5  2011-01-05       1   0     1        0        3           1   \n",
       "..       ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "726      727  2012-12-27       1   1    12        0        4           1   \n",
       "727      728  2012-12-28       1   1    12        0        5           1   \n",
       "728      729  2012-12-29       1   1    12        0        6           0   \n",
       "729      730  2012-12-30       1   1    12        0        0           0   \n",
       "730      731  2012-12-31       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0             2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1             2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2             1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3             1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4             1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "..          ...       ...       ...       ...        ...     ...         ...   \n",
       "726           2  0.254167  0.226642  0.652917   0.350133     247        1867   \n",
       "727           2  0.253333  0.255046  0.590000   0.155471     644        2451   \n",
       "728           2  0.253333  0.242400  0.752917   0.124383     159        1182   \n",
       "729           1  0.255833  0.231700  0.483333   0.350754     364        1432   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "0     985  \n",
       "1     801  \n",
       "2    1349  \n",
       "3    1562  \n",
       "4    1600  \n",
       "..    ...  \n",
       "726  2114  \n",
       "727  3095  \n",
       "728  1341  \n",
       "729  1796  \n",
       "730  2729  \n",
       "\n",
       "[731 rows x 16 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Specify the path to your CSV file including the file name\n",
    "file_path = r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv'\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "day_Bike = pd.read_csv(file_path)\n",
    "\n",
    "# Display the DataFrame\n",
    "day_Bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c37a2240",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "19/19 [==============================] - 2s 50ms/step - loss: 24461802.0000 - val_loss: 22307766.0000\n",
      "Epoch 2/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 24438028.0000 - val_loss: 22273842.0000\n",
      "Epoch 3/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 24386196.0000 - val_loss: 22206452.0000\n",
      "Epoch 4/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 24293528.0000 - val_loss: 22096256.0000\n",
      "Epoch 5/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 24153808.0000 - val_loss: 21943848.0000\n",
      "Epoch 6/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 23973686.0000 - val_loss: 21758196.0000\n",
      "Epoch 7/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 23764642.0000 - val_loss: 21552548.0000\n",
      "Epoch 8/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 23537914.0000 - val_loss: 21336938.0000\n",
      "Epoch 9/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 23305102.0000 - val_loss: 21117774.0000\n",
      "Epoch 10/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 23071618.0000 - val_loss: 20899642.0000\n",
      "Epoch 11/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 22840028.0000 - val_loss: 20688876.0000\n",
      "Epoch 12/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 22617198.0000 - val_loss: 20484544.0000\n",
      "Epoch 13/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 22399582.0000 - val_loss: 20283386.0000\n",
      "Epoch 14/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 22188474.0000 - val_loss: 20088250.0000\n",
      "Epoch 15/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 21984562.0000 - val_loss: 19903532.0000\n",
      "Epoch 16/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 21789778.0000 - val_loss: 19720508.0000\n",
      "Epoch 17/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 21596354.0000 - val_loss: 19544552.0000\n",
      "Epoch 18/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 21411404.0000 - val_loss: 19374308.0000\n",
      "Epoch 19/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 21230400.0000 - val_loss: 19209532.0000\n",
      "Epoch 20/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 21054614.0000 - val_loss: 19047390.0000\n",
      "Epoch 21/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 20884076.0000 - val_loss: 18888644.0000\n",
      "Epoch 22/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 20717032.0000 - val_loss: 18736606.0000\n",
      "Epoch 23/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 20554946.0000 - val_loss: 18587680.0000\n",
      "Epoch 24/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 20397054.0000 - val_loss: 18441768.0000\n",
      "Epoch 25/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 20241854.0000 - val_loss: 18298950.0000\n",
      "Epoch 26/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 20090406.0000 - val_loss: 18158616.0000\n",
      "Epoch 27/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 19940626.0000 - val_loss: 18021542.0000\n",
      "Epoch 28/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 19794062.0000 - val_loss: 17886456.0000\n",
      "Epoch 29/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 19649546.0000 - val_loss: 17753024.0000\n",
      "Epoch 30/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 19507050.0000 - val_loss: 17621538.0000\n",
      "Epoch 31/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 19366890.0000 - val_loss: 17489748.0000\n",
      "Epoch 32/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 19226776.0000 - val_loss: 17363540.0000\n",
      "Epoch 33/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 19092160.0000 - val_loss: 17238684.0000\n",
      "Epoch 34/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 18958750.0000 - val_loss: 17117418.0000\n",
      "Epoch 35/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 18827574.0000 - val_loss: 16996466.0000\n",
      "Epoch 36/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 18697732.0000 - val_loss: 16876074.0000\n",
      "Epoch 37/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 18570276.0000 - val_loss: 16756975.0000\n",
      "Epoch 38/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 18443148.0000 - val_loss: 16640670.0000\n",
      "Epoch 39/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 18317272.0000 - val_loss: 16524779.0000\n",
      "Epoch 40/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 18193486.0000 - val_loss: 16409746.0000\n",
      "Epoch 41/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 18070412.0000 - val_loss: 16298304.0000\n",
      "Epoch 42/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 17951256.0000 - val_loss: 16188118.0000\n",
      "Epoch 43/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 17831848.0000 - val_loss: 16079013.0000\n",
      "Epoch 44/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17715406.0000 - val_loss: 15968815.0000\n",
      "Epoch 45/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 17597062.0000 - val_loss: 15862641.0000\n",
      "Epoch 46/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17480978.0000 - val_loss: 15756048.0000\n",
      "Epoch 47/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17365606.0000 - val_loss: 15649949.0000\n",
      "Epoch 48/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 17251460.0000 - val_loss: 15544863.0000\n",
      "Epoch 49/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 17138488.0000 - val_loss: 15439903.0000\n",
      "Epoch 50/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 17026328.0000 - val_loss: 15338240.0000\n",
      "Epoch 51/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 16916194.0000 - val_loss: 15236563.0000\n",
      "Epoch 52/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16806870.0000 - val_loss: 15136305.0000\n",
      "Epoch 53/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 16698770.0000 - val_loss: 15036360.0000\n",
      "Epoch 54/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 16591488.0000 - val_loss: 14937684.0000\n",
      "Epoch 55/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 16484538.0000 - val_loss: 14840155.0000\n",
      "Epoch 56/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 16379371.0000 - val_loss: 14744217.0000\n",
      "Epoch 57/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 16274883.0000 - val_loss: 14649292.0000\n",
      "Epoch 58/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 16171578.0000 - val_loss: 14552554.0000\n",
      "Epoch 59/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 16067251.0000 - val_loss: 14458099.0000\n",
      "Epoch 60/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15964555.0000 - val_loss: 14363920.0000\n",
      "Epoch 61/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 15862752.0000 - val_loss: 14271421.0000\n",
      "Epoch 62/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 15761966.0000 - val_loss: 14177848.0000\n",
      "Epoch 63/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 15661380.0000 - val_loss: 14086273.0000\n",
      "Epoch 64/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15562452.0000 - val_loss: 13995816.0000\n",
      "Epoch 65/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 15463252.0000 - val_loss: 13905598.0000\n",
      "Epoch 66/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 15365984.0000 - val_loss: 13815169.0000\n",
      "Epoch 67/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 15268710.0000 - val_loss: 13726872.0000\n",
      "Epoch 68/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 15172508.0000 - val_loss: 13638382.0000\n",
      "Epoch 69/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 15076115.0000 - val_loss: 13552860.0000\n",
      "Epoch 70/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14982086.0000 - val_loss: 13464936.0000\n",
      "Epoch 71/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 14886660.0000 - val_loss: 13379347.0000\n",
      "Epoch 72/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14793572.0000 - val_loss: 13292619.0000\n",
      "Epoch 73/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 14699980.0000 - val_loss: 13209492.0000\n",
      "Epoch 74/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 14608992.0000 - val_loss: 13125118.0000\n",
      "Epoch 75/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14517916.0000 - val_loss: 13041183.0000\n",
      "Epoch 76/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14427192.0000 - val_loss: 12959482.0000\n",
      "Epoch 77/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 14337378.0000 - val_loss: 12877128.0000\n",
      "Epoch 78/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 14248066.0000 - val_loss: 12796054.0000\n",
      "Epoch 79/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 14158963.0000 - val_loss: 12715757.0000\n",
      "Epoch 80/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 14070668.0000 - val_loss: 12636354.0000\n",
      "Epoch 81/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 13983979.0000 - val_loss: 12556380.0000\n",
      "Epoch 82/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 13897296.0000 - val_loss: 12477026.0000\n",
      "Epoch 83/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 13809542.0000 - val_loss: 12398886.0000\n",
      "Epoch 84/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 13723163.0000 - val_loss: 12320684.0000\n",
      "Epoch 85/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 13638241.0000 - val_loss: 12242584.0000\n",
      "Epoch 86/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 13553059.0000 - val_loss: 12164645.0000\n",
      "Epoch 87/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 13468398.0000 - val_loss: 12088125.0000\n",
      "Epoch 88/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 13384410.0000 - val_loss: 12012071.0000\n",
      "Epoch 89/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 13300960.0000 - val_loss: 11937405.0000\n",
      "Epoch 90/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 13218812.0000 - val_loss: 11862367.0000\n",
      "Epoch 91/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 13135845.0000 - val_loss: 11788145.0000\n",
      "Epoch 92/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 13054219.0000 - val_loss: 11712529.0000\n",
      "Epoch 93/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 12971992.0000 - val_loss: 11639393.0000\n",
      "Epoch 94/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 12891785.0000 - val_loss: 11566669.0000\n",
      "Epoch 95/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 12811936.0000 - val_loss: 11496063.0000\n",
      "Epoch 96/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 12733627.0000 - val_loss: 11424288.0000\n",
      "Epoch 97/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 12654699.0000 - val_loss: 11352956.0000\n",
      "Epoch 98/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 12576026.0000 - val_loss: 11282072.0000\n",
      "Epoch 99/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 12498481.0000 - val_loss: 11212107.0000\n",
      "Epoch 100/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 12421351.0000 - val_loss: 11143048.0000\n",
      "Epoch 101/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 12344937.0000 - val_loss: 11073740.0000\n",
      "Epoch 102/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 12268722.0000 - val_loss: 11004778.0000\n",
      "Epoch 103/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 12193042.0000 - val_loss: 10937482.0000\n",
      "Epoch 104/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 12118098.0000 - val_loss: 10869168.0000\n",
      "Epoch 105/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 12042773.0000 - val_loss: 10801715.0000\n",
      "Epoch 106/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11968915.0000 - val_loss: 10735376.0000\n",
      "Epoch 107/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11895094.0000 - val_loss: 10669127.0000\n",
      "Epoch 108/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11822532.0000 - val_loss: 10603418.0000\n",
      "Epoch 109/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11749557.0000 - val_loss: 10538952.0000\n",
      "Epoch 110/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11678368.0000 - val_loss: 10474654.0000\n",
      "Epoch 111/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11606897.0000 - val_loss: 10411084.0000\n",
      "Epoch 112/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11535821.0000 - val_loss: 10346619.0000\n",
      "Epoch 113/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11464402.0000 - val_loss: 10283851.0000\n",
      "Epoch 114/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11394746.0000 - val_loss: 10220669.0000\n",
      "Epoch 115/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11324655.0000 - val_loss: 10158273.0000\n",
      "Epoch 116/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11255012.0000 - val_loss: 10095161.0000\n",
      "Epoch 117/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11185197.0000 - val_loss: 10033235.0000\n",
      "Epoch 118/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 11116642.0000 - val_loss: 9970789.0000\n",
      "Epoch 119/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 11047844.0000 - val_loss: 9910664.0000\n",
      "Epoch 120/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10981009.0000 - val_loss: 9850132.0000\n",
      "Epoch 121/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10913791.0000 - val_loss: 9790302.0000\n",
      "Epoch 122/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 10847048.0000 - val_loss: 9731219.0000\n",
      "Epoch 123/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10781170.0000 - val_loss: 9672041.0000\n",
      "Epoch 124/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 10714533.0000 - val_loss: 9613649.0000\n",
      "Epoch 125/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 10648720.0000 - val_loss: 9555501.0000\n",
      "Epoch 126/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10583142.0000 - val_loss: 9496313.0000\n",
      "Epoch 127/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 10517493.0000 - val_loss: 9437428.0000\n",
      "Epoch 128/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10452775.0000 - val_loss: 9379669.0000\n",
      "Epoch 129/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10389111.0000 - val_loss: 9323316.0000\n",
      "Epoch 130/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 10324829.0000 - val_loss: 9267350.0000\n",
      "Epoch 131/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 10261882.0000 - val_loss: 9210490.0000\n",
      "Epoch 132/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10198404.0000 - val_loss: 9155043.0000\n",
      "Epoch 133/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 10136284.0000 - val_loss: 9099712.0000\n",
      "Epoch 134/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 10074832.0000 - val_loss: 9044175.0000\n",
      "Epoch 135/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 10013034.0000 - val_loss: 8991216.0000\n",
      "Epoch 136/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9953358.0000 - val_loss: 8937991.0000\n",
      "Epoch 137/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9892629.0000 - val_loss: 8884652.0000\n",
      "Epoch 138/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 9832470.0000 - val_loss: 8830872.0000\n",
      "Epoch 139/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9772335.0000 - val_loss: 8778607.0000\n",
      "Epoch 140/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9712893.0000 - val_loss: 8725689.0000\n",
      "Epoch 141/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 9653991.0000 - val_loss: 8672972.0000\n",
      "Epoch 142/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9594291.0000 - val_loss: 8620580.0000\n",
      "Epoch 143/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 9535778.0000 - val_loss: 8569197.0000\n",
      "Epoch 144/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9477749.0000 - val_loss: 8517990.0000\n",
      "Epoch 145/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9419690.0000 - val_loss: 8468065.0000\n",
      "Epoch 146/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9363089.0000 - val_loss: 8417844.0000\n",
      "Epoch 147/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 9306811.0000 - val_loss: 8368163.5000\n",
      "Epoch 148/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9250628.0000 - val_loss: 8319531.5000\n",
      "Epoch 149/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9195537.0000 - val_loss: 8271069.0000\n",
      "Epoch 150/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9140107.0000 - val_loss: 8221835.5000\n",
      "Epoch 151/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9083914.0000 - val_loss: 8173215.5000\n",
      "Epoch 152/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 9028818.0000 - val_loss: 8124768.0000\n",
      "Epoch 153/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8973833.0000 - val_loss: 8076862.5000\n",
      "Epoch 154/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8919463.0000 - val_loss: 8030026.0000\n",
      "Epoch 155/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 8865726.0000 - val_loss: 7983293.0000\n",
      "Epoch 156/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8813196.0000 - val_loss: 7936353.5000\n",
      "Epoch 157/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8760332.0000 - val_loss: 7890549.5000\n",
      "Epoch 158/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8707713.0000 - val_loss: 7844185.5000\n",
      "Epoch 159/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8654964.0000 - val_loss: 7799671.5000\n",
      "Epoch 160/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8603872.0000 - val_loss: 7753959.5000\n",
      "Epoch 161/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8552443.0000 - val_loss: 7709251.0000\n",
      "Epoch 162/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8500948.0000 - val_loss: 7664842.0000\n",
      "Epoch 163/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 8450139.0000 - val_loss: 7620129.0000\n",
      "Epoch 164/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8399587.0000 - val_loss: 7576243.5000\n",
      "Epoch 165/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 8349008.5000 - val_loss: 7533057.5000\n",
      "Epoch 166/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8299024.5000 - val_loss: 7490438.0000\n",
      "Epoch 167/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8250673.0000 - val_loss: 7448136.5000\n",
      "Epoch 168/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8201270.5000 - val_loss: 7405477.5000\n",
      "Epoch 169/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 8151798.5000 - val_loss: 7363665.0000\n",
      "Epoch 170/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8103746.5000 - val_loss: 7320537.0000\n",
      "Epoch 171/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8054245.0000 - val_loss: 7279687.0000\n",
      "Epoch 172/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 8006683.0000 - val_loss: 7237748.5000\n",
      "Epoch 173/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7958925.0000 - val_loss: 7196150.5000\n",
      "Epoch 174/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7911389.0000 - val_loss: 7155649.5000\n",
      "Epoch 175/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7864599.0000 - val_loss: 7115906.5000\n",
      "Epoch 176/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7818355.5000 - val_loss: 7076537.5000\n",
      "Epoch 177/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 7772600.0000 - val_loss: 7036771.5000\n",
      "Epoch 178/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7726416.5000 - val_loss: 6997044.0000\n",
      "Epoch 179/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7681008.0000 - val_loss: 6957976.5000\n",
      "Epoch 180/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7634933.5000 - val_loss: 6918940.0000\n",
      "Epoch 181/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7590500.0000 - val_loss: 6881132.0000\n",
      "Epoch 182/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7545918.0000 - val_loss: 6843879.5000\n",
      "Epoch 183/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7501978.5000 - val_loss: 6805122.5000\n",
      "Epoch 184/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7456630.5000 - val_loss: 6767592.5000\n",
      "Epoch 185/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7413124.5000 - val_loss: 6730467.0000\n",
      "Epoch 186/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7370115.5000 - val_loss: 6693772.5000\n",
      "Epoch 187/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7327071.0000 - val_loss: 6657171.0000\n",
      "Epoch 188/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 7284019.0000 - val_loss: 6620997.5000\n",
      "Epoch 189/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7241852.5000 - val_loss: 6584013.5000\n",
      "Epoch 190/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7199134.0000 - val_loss: 6548812.0000\n",
      "Epoch 191/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 7157653.0000 - val_loss: 6514184.0000\n",
      "Epoch 192/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 7116708.0000 - val_loss: 6479445.5000\n",
      "Epoch 193/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 7076123.0000 - val_loss: 6444020.5000\n",
      "Epoch 194/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 7034941.5000 - val_loss: 6410052.0000\n",
      "Epoch 195/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6994620.0000 - val_loss: 6376030.5000\n",
      "Epoch 196/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6953569.0000 - val_loss: 6342538.0000\n",
      "Epoch 197/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6913668.5000 - val_loss: 6308962.0000\n",
      "Epoch 198/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6874081.5000 - val_loss: 6275416.5000\n",
      "Epoch 199/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6834625.5000 - val_loss: 6242610.5000\n",
      "Epoch 200/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6795702.5000 - val_loss: 6209558.0000\n",
      "Epoch 201/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6756935.5000 - val_loss: 6177121.0000\n",
      "Epoch 202/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6717450.5000 - val_loss: 6144385.5000\n",
      "Epoch 203/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 6679124.5000 - val_loss: 6111900.0000\n",
      "Epoch 204/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6640812.0000 - val_loss: 6081197.0000\n",
      "Epoch 205/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6602799.5000 - val_loss: 6049608.0000\n",
      "Epoch 206/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6565285.5000 - val_loss: 6018412.5000\n",
      "Epoch 207/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 6527916.0000 - val_loss: 5987349.5000\n",
      "Epoch 208/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6490570.5000 - val_loss: 5955663.5000\n",
      "Epoch 209/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6452974.5000 - val_loss: 5924741.5000\n",
      "Epoch 210/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6415360.5000 - val_loss: 5894540.0000\n",
      "Epoch 211/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6378755.5000 - val_loss: 5863468.5000\n",
      "Epoch 212/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 6341377.0000 - val_loss: 5832295.0000\n",
      "Epoch 213/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6303959.0000 - val_loss: 5802016.0000\n",
      "Epoch 214/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6266855.0000 - val_loss: 5770914.0000\n",
      "Epoch 215/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6228798.0000 - val_loss: 5739065.5000\n",
      "Epoch 216/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6188997.0000 - val_loss: 5704749.5000\n",
      "Epoch 217/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6146954.5000 - val_loss: 5666565.0000\n",
      "Epoch 218/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 6100602.5000 - val_loss: 5623822.0000\n",
      "Epoch 219/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 6048657.5000 - val_loss: 5573315.5000\n",
      "Epoch 220/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5992649.0000 - val_loss: 5517775.0000\n",
      "Epoch 221/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5933391.0000 - val_loss: 5462148.0000\n",
      "Epoch 222/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5876022.5000 - val_loss: 5408022.5000\n",
      "Epoch 223/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5820981.0000 - val_loss: 5360560.5000\n",
      "Epoch 224/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5769929.0000 - val_loss: 5317462.0000\n",
      "Epoch 225/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5722070.5000 - val_loss: 5278409.0000\n",
      "Epoch 226/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5677811.5000 - val_loss: 5241117.5000\n",
      "Epoch 227/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5635010.0000 - val_loss: 5205902.5000\n",
      "Epoch 228/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5593807.0000 - val_loss: 5171178.0000\n",
      "Epoch 229/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5553414.0000 - val_loss: 5139263.0000\n",
      "Epoch 230/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5514140.0000 - val_loss: 5106908.5000\n",
      "Epoch 231/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5475393.0000 - val_loss: 5075545.5000\n",
      "Epoch 232/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 5436421.0000 - val_loss: 5044281.0000\n",
      "Epoch 233/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 5399113.5000 - val_loss: 5012178.5000\n",
      "Epoch 234/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5361995.5000 - val_loss: 4981058.5000\n",
      "Epoch 235/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5325459.0000 - val_loss: 4950351.0000\n",
      "Epoch 236/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5288762.5000 - val_loss: 4921080.0000\n",
      "Epoch 237/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5252679.0000 - val_loss: 4890660.0000\n",
      "Epoch 238/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5216037.5000 - val_loss: 4859860.5000\n",
      "Epoch 239/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5179250.0000 - val_loss: 4829358.5000\n",
      "Epoch 240/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5143873.0000 - val_loss: 4799904.0000\n",
      "Epoch 241/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5109262.0000 - val_loss: 4771050.0000\n",
      "Epoch 242/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 5074752.5000 - val_loss: 4741928.5000\n",
      "Epoch 243/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5040396.5000 - val_loss: 4713688.0000\n",
      "Epoch 244/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 5006179.0000 - val_loss: 4684955.0000\n",
      "Epoch 245/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4972445.5000 - val_loss: 4657183.0000\n",
      "Epoch 246/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4938389.0000 - val_loss: 4629330.5000\n",
      "Epoch 247/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4905299.5000 - val_loss: 4600699.5000\n",
      "Epoch 248/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4872192.0000 - val_loss: 4572138.0000\n",
      "Epoch 249/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4839788.5000 - val_loss: 4545392.5000\n",
      "Epoch 250/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4807452.0000 - val_loss: 4518216.0000\n",
      "Epoch 251/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4774832.5000 - val_loss: 4489800.5000\n",
      "Epoch 252/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4742981.0000 - val_loss: 4462267.0000\n",
      "Epoch 253/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4710156.5000 - val_loss: 4436133.0000\n",
      "Epoch 254/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4678867.5000 - val_loss: 4408697.0000\n",
      "Epoch 255/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4647029.0000 - val_loss: 4381499.0000\n",
      "Epoch 256/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4615739.0000 - val_loss: 4354482.5000\n",
      "Epoch 257/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4584281.0000 - val_loss: 4327251.5000\n",
      "Epoch 258/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 4553300.0000 - val_loss: 4300719.0000\n",
      "Epoch 259/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4522487.5000 - val_loss: 4275572.0000\n",
      "Epoch 260/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4492014.5000 - val_loss: 4247922.5000\n",
      "Epoch 261/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4460579.0000 - val_loss: 4222413.0000\n",
      "Epoch 262/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4429985.0000 - val_loss: 4193217.2500\n",
      "Epoch 263/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4400110.0000 - val_loss: 4167294.7500\n",
      "Epoch 264/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4369285.0000 - val_loss: 4142834.0000\n",
      "Epoch 265/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4340112.5000 - val_loss: 4116325.0000\n",
      "Epoch 266/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4310669.5000 - val_loss: 4090878.7500\n",
      "Epoch 267/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4280461.5000 - val_loss: 4066315.0000\n",
      "Epoch 268/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4251363.0000 - val_loss: 4039703.5000\n",
      "Epoch 269/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 4221189.5000 - val_loss: 4013210.5000\n",
      "Epoch 270/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 4191300.0000 - val_loss: 3988360.7500\n",
      "Epoch 271/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 4162577.0000 - val_loss: 3962063.2500\n",
      "Epoch 272/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4132735.0000 - val_loss: 3937509.5000\n",
      "Epoch 273/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4104279.7500 - val_loss: 3911733.5000\n",
      "Epoch 274/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4074919.0000 - val_loss: 3885988.2500\n",
      "Epoch 275/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4045554.0000 - val_loss: 3860871.7500\n",
      "Epoch 276/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 4017576.7500 - val_loss: 3835306.2500\n",
      "Epoch 277/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3989032.0000 - val_loss: 3814766.2500\n",
      "Epoch 278/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3960436.2500 - val_loss: 3789515.2500\n",
      "Epoch 279/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3932239.2500 - val_loss: 3764319.2500\n",
      "Epoch 280/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3903927.2500 - val_loss: 3739662.0000\n",
      "Epoch 281/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3876055.2500 - val_loss: 3715762.5000\n",
      "Epoch 282/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3847765.5000 - val_loss: 3690861.7500\n",
      "Epoch 283/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 3820460.2500 - val_loss: 3668004.2500\n",
      "Epoch 284/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3792610.7500 - val_loss: 3644248.0000\n",
      "Epoch 285/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3765569.0000 - val_loss: 3620448.2500\n",
      "Epoch 286/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3738619.2500 - val_loss: 3596836.7500\n",
      "Epoch 287/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3711969.7500 - val_loss: 3574055.0000\n",
      "Epoch 288/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3685746.0000 - val_loss: 3551611.5000\n",
      "Epoch 289/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3659832.0000 - val_loss: 3526981.0000\n",
      "Epoch 290/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3633436.2500 - val_loss: 3505953.5000\n",
      "Epoch 291/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3607730.0000 - val_loss: 3483554.5000\n",
      "Epoch 292/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3582836.7500 - val_loss: 3460511.2500\n",
      "Epoch 293/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 3557480.7500 - val_loss: 3439073.7500\n",
      "Epoch 294/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3532117.7500 - val_loss: 3418122.0000\n",
      "Epoch 295/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3507471.0000 - val_loss: 3396953.7500\n",
      "Epoch 296/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3482845.7500 - val_loss: 3374122.0000\n",
      "Epoch 297/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 3458268.2500 - val_loss: 3353052.0000\n",
      "Epoch 298/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3434046.7500 - val_loss: 3331660.5000\n",
      "Epoch 299/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3409754.0000 - val_loss: 3311463.0000\n",
      "Epoch 300/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3385822.7500 - val_loss: 3290040.0000\n",
      "Epoch 301/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3361661.2500 - val_loss: 3267391.0000\n",
      "Epoch 302/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3337774.2500 - val_loss: 3245920.7500\n",
      "Epoch 303/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3314679.0000 - val_loss: 3224627.2500\n",
      "Epoch 304/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3291373.0000 - val_loss: 3204509.2500\n",
      "Epoch 305/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3268489.7500 - val_loss: 3185466.7500\n",
      "Epoch 306/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3246767.7500 - val_loss: 3163412.2500\n",
      "Epoch 307/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3223334.2500 - val_loss: 3145390.2500\n",
      "Epoch 308/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3200534.7500 - val_loss: 3125711.7500\n",
      "Epoch 309/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3178596.7500 - val_loss: 3108495.7500\n",
      "Epoch 310/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3156759.5000 - val_loss: 3086737.5000\n",
      "Epoch 311/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3134465.7500 - val_loss: 3066173.7500\n",
      "Epoch 312/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 3113314.5000 - val_loss: 3045733.7500\n",
      "Epoch 313/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3091577.5000 - val_loss: 3025956.7500\n",
      "Epoch 314/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3070462.5000 - val_loss: 3005466.7500\n",
      "Epoch 315/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 3049497.7500 - val_loss: 2985375.0000\n",
      "Epoch 316/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3028682.2500 - val_loss: 2965970.2500\n",
      "Epoch 317/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 3007393.0000 - val_loss: 2945537.0000\n",
      "Epoch 318/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2986790.0000 - val_loss: 2925219.5000\n",
      "Epoch 319/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2966077.0000 - val_loss: 2905730.5000\n",
      "Epoch 320/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2945911.7500 - val_loss: 2885493.7500\n",
      "Epoch 321/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2925294.5000 - val_loss: 2867368.2500\n",
      "Epoch 322/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2905158.5000 - val_loss: 2848687.0000\n",
      "Epoch 323/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2884939.5000 - val_loss: 2828996.2500\n",
      "Epoch 324/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2865328.5000 - val_loss: 2812182.5000\n",
      "Epoch 325/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2846025.5000 - val_loss: 2792857.5000\n",
      "Epoch 326/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2826568.2500 - val_loss: 2771558.0000\n",
      "Epoch 327/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2806971.5000 - val_loss: 2749402.7500\n",
      "Epoch 328/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2787323.2500 - val_loss: 2733516.7500\n",
      "Epoch 329/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2767348.0000 - val_loss: 2713518.5000\n",
      "Epoch 330/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2747296.0000 - val_loss: 2691260.0000\n",
      "Epoch 331/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2728577.0000 - val_loss: 2673754.7500\n",
      "Epoch 332/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2710322.7500 - val_loss: 2654731.0000\n",
      "Epoch 333/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2690964.0000 - val_loss: 2638692.2500\n",
      "Epoch 334/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2672964.5000 - val_loss: 2621221.7500\n",
      "Epoch 335/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2655094.2500 - val_loss: 2605749.0000\n",
      "Epoch 336/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2637070.0000 - val_loss: 2587514.7500\n",
      "Epoch 337/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2619025.0000 - val_loss: 2570110.2500\n",
      "Epoch 338/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2601552.0000 - val_loss: 2551230.7500\n",
      "Epoch 339/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2583590.2500 - val_loss: 2535425.0000\n",
      "Epoch 340/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2565282.7500 - val_loss: 2516866.0000\n",
      "Epoch 341/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2547606.5000 - val_loss: 2499014.7500\n",
      "Epoch 342/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2530773.5000 - val_loss: 2481508.2500\n",
      "Epoch 343/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2513311.5000 - val_loss: 2466378.2500\n",
      "Epoch 344/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2497053.0000 - val_loss: 2445131.7500\n",
      "Epoch 345/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2479338.0000 - val_loss: 2431308.5000\n",
      "Epoch 346/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2463267.2500 - val_loss: 2413939.7500\n",
      "Epoch 347/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 2446306.0000 - val_loss: 2400667.7500\n",
      "Epoch 348/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2430094.7500 - val_loss: 2382619.7500\n",
      "Epoch 349/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2413075.7500 - val_loss: 2364364.5000\n",
      "Epoch 350/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2396867.7500 - val_loss: 2352062.7500\n",
      "Epoch 351/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2381277.0000 - val_loss: 2336310.0000\n",
      "Epoch 352/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2364211.7500 - val_loss: 2318250.0000\n",
      "Epoch 353/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2348273.5000 - val_loss: 2303916.5000\n",
      "Epoch 354/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 2332413.2500 - val_loss: 2287926.2500\n",
      "Epoch 355/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2317186.7500 - val_loss: 2275781.0000\n",
      "Epoch 356/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2302154.0000 - val_loss: 2256420.7500\n",
      "Epoch 357/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2285904.2500 - val_loss: 2242429.2500\n",
      "Epoch 358/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2270718.0000 - val_loss: 2229081.7500\n",
      "Epoch 359/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2255828.5000 - val_loss: 2211879.0000\n",
      "Epoch 360/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2240942.2500 - val_loss: 2197340.7500\n",
      "Epoch 361/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 2226081.0000 - val_loss: 2181290.0000\n",
      "Epoch 362/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2211380.0000 - val_loss: 2166923.2500\n",
      "Epoch 363/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2196856.7500 - val_loss: 2155250.2500\n",
      "Epoch 364/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2182069.5000 - val_loss: 2139055.0000\n",
      "Epoch 365/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2167732.2500 - val_loss: 2125436.2500\n",
      "Epoch 366/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2153831.7500 - val_loss: 2112499.2500\n",
      "Epoch 367/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2139699.2500 - val_loss: 2095068.5000\n",
      "Epoch 368/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2125874.0000 - val_loss: 2081793.1250\n",
      "Epoch 369/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2112392.0000 - val_loss: 2072306.5000\n",
      "Epoch 370/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2098575.5000 - val_loss: 2061417.1250\n",
      "Epoch 371/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2084849.5000 - val_loss: 2043866.3750\n",
      "Epoch 372/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2070963.2500 - val_loss: 2030708.6250\n",
      "Epoch 373/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 2057723.3750 - val_loss: 2017097.3750\n",
      "Epoch 374/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2044519.5000 - val_loss: 2006012.5000\n",
      "Epoch 375/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2031765.2500 - val_loss: 1994486.6250\n",
      "Epoch 376/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2019331.7500 - val_loss: 1981097.1250\n",
      "Epoch 377/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 2006112.8750 - val_loss: 1967273.7500\n",
      "Epoch 378/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1992991.1250 - val_loss: 1954193.3750\n",
      "Epoch 379/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1980355.7500 - val_loss: 1940540.5000\n",
      "Epoch 380/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1967768.1250 - val_loss: 1927000.3750\n",
      "Epoch 381/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1955283.5000 - val_loss: 1912308.5000\n",
      "Epoch 382/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1943248.6250 - val_loss: 1903389.1250\n",
      "Epoch 383/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1930061.6250 - val_loss: 1892364.8750\n",
      "Epoch 384/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1917937.5000 - val_loss: 1880485.8750\n",
      "Epoch 385/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1905929.2500 - val_loss: 1869425.8750\n",
      "Epoch 386/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1894310.7500 - val_loss: 1853693.8750\n",
      "Epoch 387/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1881910.6250 - val_loss: 1842548.6250\n",
      "Epoch 388/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1870632.1250 - val_loss: 1832570.7500\n",
      "Epoch 389/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1858718.0000 - val_loss: 1820085.6250\n",
      "Epoch 390/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1846997.0000 - val_loss: 1808242.1250\n",
      "Epoch 391/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1835953.5000 - val_loss: 1796426.5000\n",
      "Epoch 392/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1823830.2500 - val_loss: 1786888.1250\n",
      "Epoch 393/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1812744.7500 - val_loss: 1776697.2500\n",
      "Epoch 394/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1802690.0000 - val_loss: 1768352.8750\n",
      "Epoch 395/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1790874.3750 - val_loss: 1753469.3750\n",
      "Epoch 396/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1779493.1250 - val_loss: 1743745.2500\n",
      "Epoch 397/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1768353.3750 - val_loss: 1732562.3750\n",
      "Epoch 398/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1757500.5000 - val_loss: 1722178.5000\n",
      "Epoch 399/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1746294.3750 - val_loss: 1709420.2500\n",
      "Epoch 400/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1735983.6250 - val_loss: 1698769.5000\n",
      "Epoch 401/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1725523.3750 - val_loss: 1689423.5000\n",
      "Epoch 402/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1715782.8750 - val_loss: 1676695.1250\n",
      "Epoch 403/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1704437.2500 - val_loss: 1672642.5000\n",
      "Epoch 404/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1694957.0000 - val_loss: 1664603.5000\n",
      "Epoch 405/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1684511.5000 - val_loss: 1653226.8750\n",
      "Epoch 406/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1674656.7500 - val_loss: 1641206.0000\n",
      "Epoch 407/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1664883.1250 - val_loss: 1629725.8750\n",
      "Epoch 408/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1655108.5000 - val_loss: 1621472.1250\n",
      "Epoch 409/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1645259.1250 - val_loss: 1611597.8750\n",
      "Epoch 410/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1635384.6250 - val_loss: 1603699.7500\n",
      "Epoch 411/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1626071.1250 - val_loss: 1594498.1250\n",
      "Epoch 412/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1616597.2500 - val_loss: 1583917.2500\n",
      "Epoch 413/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1607775.5000 - val_loss: 1578228.6250\n",
      "Epoch 414/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1597263.0000 - val_loss: 1567543.1250\n",
      "Epoch 415/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1588588.8750 - val_loss: 1556620.8750\n",
      "Epoch 416/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1579228.8750 - val_loss: 1550412.0000\n",
      "Epoch 417/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1569582.6250 - val_loss: 1539950.3750\n",
      "Epoch 418/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1560520.5000 - val_loss: 1531467.7500\n",
      "Epoch 419/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1551600.7500 - val_loss: 1518931.0000\n",
      "Epoch 420/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1542146.5000 - val_loss: 1511629.2500\n",
      "Epoch 421/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1533241.3750 - val_loss: 1504239.8750\n",
      "Epoch 422/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1524202.7500 - val_loss: 1495736.0000\n",
      "Epoch 423/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1515269.2500 - val_loss: 1489650.8750\n",
      "Epoch 424/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1506957.2500 - val_loss: 1484055.1250\n",
      "Epoch 425/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 1498118.7500 - val_loss: 1475013.1250\n",
      "Epoch 426/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1489293.5000 - val_loss: 1465208.1250\n",
      "Epoch 427/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1481124.1250 - val_loss: 1456014.1250\n",
      "Epoch 428/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1472265.7500 - val_loss: 1445163.2500\n",
      "Epoch 429/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1464063.5000 - val_loss: 1439413.8750\n",
      "Epoch 430/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 1455084.8750 - val_loss: 1430785.3750\n",
      "Epoch 431/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1446785.8750 - val_loss: 1421627.8750\n",
      "Epoch 432/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 1438291.3750 - val_loss: 1413656.0000\n",
      "Epoch 433/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1430815.3750 - val_loss: 1408151.1250\n",
      "Epoch 434/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1421980.0000 - val_loss: 1400500.3750\n",
      "Epoch 435/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1413807.7500 - val_loss: 1390944.2500\n",
      "Epoch 436/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1407400.6250 - val_loss: 1383137.0000\n",
      "Epoch 437/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1398057.5000 - val_loss: 1377782.1250\n",
      "Epoch 438/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1390731.6250 - val_loss: 1373162.0000\n",
      "Epoch 439/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1382823.7500 - val_loss: 1364279.1250\n",
      "Epoch 440/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1375353.1250 - val_loss: 1357093.1250\n",
      "Epoch 441/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1367980.6250 - val_loss: 1349872.3750\n",
      "Epoch 442/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1360310.0000 - val_loss: 1342461.5000\n",
      "Epoch 443/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1352780.7500 - val_loss: 1335383.8750\n",
      "Epoch 444/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1345285.0000 - val_loss: 1328157.8750\n",
      "Epoch 445/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1337960.6250 - val_loss: 1323444.8750\n",
      "Epoch 446/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1330804.2500 - val_loss: 1317535.6250\n",
      "Epoch 447/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1323316.8750 - val_loss: 1310175.7500\n",
      "Epoch 448/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1316097.8750 - val_loss: 1302353.2500\n",
      "Epoch 449/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1309181.6250 - val_loss: 1294747.6250\n",
      "Epoch 450/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1302297.2500 - val_loss: 1288607.8750\n",
      "Epoch 451/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1295161.7500 - val_loss: 1282194.8750\n",
      "Epoch 452/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1288125.3750 - val_loss: 1276021.3750\n",
      "Epoch 453/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1281173.6250 - val_loss: 1269130.8750\n",
      "Epoch 454/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1273912.3750 - val_loss: 1263966.8750\n",
      "Epoch 455/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1267078.6250 - val_loss: 1258843.6250\n",
      "Epoch 456/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1260288.2500 - val_loss: 1249881.6250\n",
      "Epoch 457/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1253838.6250 - val_loss: 1243982.6250\n",
      "Epoch 458/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1246685.1250 - val_loss: 1237644.7500\n",
      "Epoch 459/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1240849.0000 - val_loss: 1230225.0000\n",
      "Epoch 460/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1233399.6250 - val_loss: 1225912.6250\n",
      "Epoch 461/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1227296.5000 - val_loss: 1221710.6250\n",
      "Epoch 462/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1220455.1250 - val_loss: 1214591.3750\n",
      "Epoch 463/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1214267.6250 - val_loss: 1207837.5000\n",
      "Epoch 464/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1207685.0000 - val_loss: 1201326.8750\n",
      "Epoch 465/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1201416.5000 - val_loss: 1195362.1250\n",
      "Epoch 466/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1194878.1250 - val_loss: 1189995.0000\n",
      "Epoch 467/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1188278.7500 - val_loss: 1184685.0000\n",
      "Epoch 468/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1182065.7500 - val_loss: 1177601.1250\n",
      "Epoch 469/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1175643.1250 - val_loss: 1172539.3750\n",
      "Epoch 470/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1169515.1250 - val_loss: 1166094.3750\n",
      "Epoch 471/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1163256.1250 - val_loss: 1161390.5000\n",
      "Epoch 472/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1157224.8750 - val_loss: 1157345.3750\n",
      "Epoch 473/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1151558.5000 - val_loss: 1153273.7500\n",
      "Epoch 474/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1144505.3750 - val_loss: 1144801.7500\n",
      "Epoch 475/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1139012.3750 - val_loss: 1138432.0000\n",
      "Epoch 476/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1132487.5000 - val_loss: 1132701.0000\n",
      "Epoch 477/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1126435.3750 - val_loss: 1128428.6250\n",
      "Epoch 478/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 1120281.0000 - val_loss: 1123371.0000\n",
      "Epoch 479/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1115083.8750 - val_loss: 1119403.5000\n",
      "Epoch 480/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1108610.2500 - val_loss: 1111877.5000\n",
      "Epoch 481/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1102419.8750 - val_loss: 1105923.3750\n",
      "Epoch 482/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1096265.2500 - val_loss: 1099018.5000\n",
      "Epoch 483/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1090566.0000 - val_loss: 1094351.3750\n",
      "Epoch 484/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1084998.5000 - val_loss: 1088688.3750\n",
      "Epoch 485/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1078920.7500 - val_loss: 1082411.2500\n",
      "Epoch 486/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1073324.3750 - val_loss: 1077533.6250\n",
      "Epoch 487/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1067642.6250 - val_loss: 1071588.5000\n",
      "Epoch 488/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1062717.7500 - val_loss: 1064837.8750\n",
      "Epoch 489/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1057525.7500 - val_loss: 1062231.5000\n",
      "Epoch 490/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1051154.3750 - val_loss: 1057467.3750\n",
      "Epoch 491/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1045648.8750 - val_loss: 1054347.7500\n",
      "Epoch 492/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1040307.7500 - val_loss: 1048763.1250\n",
      "Epoch 493/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1034759.8750 - val_loss: 1045063.3125\n",
      "Epoch 494/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 1029463.4375 - val_loss: 1038039.8125\n",
      "Epoch 495/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1023807.3125 - val_loss: 1033000.1875\n",
      "Epoch 496/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 1018529.4375 - val_loss: 1028565.5625\n",
      "Epoch 497/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 1013047.2500 - val_loss: 1021648.1250\n",
      "Epoch 498/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1007937.5625 - val_loss: 1015883.0000\n",
      "Epoch 499/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 1002805.0625 - val_loss: 1011529.5625\n",
      "Epoch 500/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 997573.8125 - val_loss: 1006064.8750\n",
      "Epoch 501/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 992470.8125 - val_loss: 999501.8125\n",
      "Epoch 502/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 986835.9375 - val_loss: 995384.5000\n",
      "Epoch 503/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 981906.6250 - val_loss: 990829.6875\n",
      "Epoch 504/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 976270.1250 - val_loss: 985923.0625\n",
      "Epoch 505/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 971606.0000 - val_loss: 981368.6875\n",
      "Epoch 506/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 966613.0625 - val_loss: 973746.0625\n",
      "Epoch 507/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 962062.2500 - val_loss: 972070.1875\n",
      "Epoch 508/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 956914.6250 - val_loss: 967068.8125\n",
      "Epoch 509/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 951883.0625 - val_loss: 964414.5000\n",
      "Epoch 510/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 946581.5625 - val_loss: 959916.5000\n",
      "Epoch 511/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 941779.8125 - val_loss: 955119.3750\n",
      "Epoch 512/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 936482.0000 - val_loss: 948492.4375\n",
      "Epoch 513/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 931994.7500 - val_loss: 943580.6250\n",
      "Epoch 514/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 927196.5000 - val_loss: 938983.1875\n",
      "Epoch 515/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 922241.5625 - val_loss: 934163.0625\n",
      "Epoch 516/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 917519.5000 - val_loss: 930239.4375\n",
      "Epoch 517/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 913640.0625 - val_loss: 925775.2500\n",
      "Epoch 518/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 908504.3125 - val_loss: 924222.6875\n",
      "Epoch 519/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 903374.1250 - val_loss: 916819.5000\n",
      "Epoch 520/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 898388.8125 - val_loss: 912182.4375\n",
      "Epoch 521/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 894044.2500 - val_loss: 907947.3750\n",
      "Epoch 522/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 889097.4375 - val_loss: 902942.5000\n",
      "Epoch 523/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 884733.2500 - val_loss: 899016.0625\n",
      "Epoch 524/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 879941.1875 - val_loss: 894318.6875\n",
      "Epoch 525/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 875264.5625 - val_loss: 889242.7500\n",
      "Epoch 526/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 871003.7500 - val_loss: 885492.5000\n",
      "Epoch 527/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 866402.3125 - val_loss: 878797.9375\n",
      "Epoch 528/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 862341.5000 - val_loss: 875839.8125\n",
      "Epoch 529/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 857829.4375 - val_loss: 871985.1250\n",
      "Epoch 530/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 852854.0625 - val_loss: 865258.3125\n",
      "Epoch 531/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 849134.0000 - val_loss: 861715.1875\n",
      "Epoch 532/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 844870.0625 - val_loss: 858628.5625\n",
      "Epoch 533/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 840150.0625 - val_loss: 853567.4375\n",
      "Epoch 534/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 836678.6875 - val_loss: 849808.6875\n",
      "Epoch 535/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 831843.3750 - val_loss: 844915.5625\n",
      "Epoch 536/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 827621.5625 - val_loss: 841885.8125\n",
      "Epoch 537/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 823807.0625 - val_loss: 835064.0625\n",
      "Epoch 538/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 819529.6250 - val_loss: 832718.6875\n",
      "Epoch 539/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 815866.1875 - val_loss: 829565.9375\n",
      "Epoch 540/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 811898.2500 - val_loss: 826673.7500\n",
      "Epoch 541/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 808265.3125 - val_loss: 822633.6250\n",
      "Epoch 542/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 803721.6250 - val_loss: 817234.7500\n",
      "Epoch 543/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 799876.9375 - val_loss: 814413.8750\n",
      "Epoch 544/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 796016.6875 - val_loss: 811265.0625\n",
      "Epoch 545/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 792705.0625 - val_loss: 805840.1875\n",
      "Epoch 546/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 790035.2500 - val_loss: 804549.3125\n",
      "Epoch 547/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 784971.6250 - val_loss: 799820.9375\n",
      "Epoch 548/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 781704.9375 - val_loss: 796033.8750\n",
      "Epoch 549/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 777309.5000 - val_loss: 791800.9375\n",
      "Epoch 550/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 774291.5000 - val_loss: 789146.6250\n",
      "Epoch 551/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 770316.0625 - val_loss: 783892.1250\n",
      "Epoch 552/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 766794.5000 - val_loss: 780394.9375\n",
      "Epoch 553/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 763225.8750 - val_loss: 776638.5000\n",
      "Epoch 554/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 759604.6875 - val_loss: 772466.3125\n",
      "Epoch 555/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 756557.1250 - val_loss: 769263.6250\n",
      "Epoch 556/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 753347.2500 - val_loss: 767762.8750\n",
      "Epoch 557/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 749496.0000 - val_loss: 762673.5000\n",
      "Epoch 558/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 746190.7500 - val_loss: 760251.7500\n",
      "Epoch 559/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 743323.2500 - val_loss: 757181.6250\n",
      "Epoch 560/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 739514.4375 - val_loss: 752226.7500\n",
      "Epoch 561/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 736807.4375 - val_loss: 749331.4375\n",
      "Epoch 562/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 733569.0625 - val_loss: 746791.4375\n",
      "Epoch 563/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 730532.5625 - val_loss: 744353.5000\n",
      "Epoch 564/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 727026.9375 - val_loss: 742594.0625\n",
      "Epoch 565/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 724397.3750 - val_loss: 739569.5000\n",
      "Epoch 566/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 721261.7500 - val_loss: 737596.7500\n",
      "Epoch 567/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 717912.5000 - val_loss: 733025.1875\n",
      "Epoch 568/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 715069.3750 - val_loss: 728999.1250\n",
      "Epoch 569/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 711860.5625 - val_loss: 726943.8750\n",
      "Epoch 570/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 709003.3750 - val_loss: 723737.5000\n",
      "Epoch 571/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 706866.6250 - val_loss: 719802.2500\n",
      "Epoch 572/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 703874.1250 - val_loss: 718367.1250\n",
      "Epoch 573/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 700283.2500 - val_loss: 714151.1875\n",
      "Epoch 574/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 697475.8125 - val_loss: 711028.8750\n",
      "Epoch 575/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 694939.6875 - val_loss: 708192.9375\n",
      "Epoch 576/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 692249.1250 - val_loss: 706172.7500\n",
      "Epoch 577/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 689034.1250 - val_loss: 703242.2500\n",
      "Epoch 578/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 686318.5000 - val_loss: 700912.1875\n",
      "Epoch 579/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 683847.7500 - val_loss: 699123.2500\n",
      "Epoch 580/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 681562.3750 - val_loss: 696300.0000\n",
      "Epoch 581/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 678671.5625 - val_loss: 692731.3750\n",
      "Epoch 582/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 676436.1250 - val_loss: 691157.5625\n",
      "Epoch 583/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 673414.4375 - val_loss: 687207.5625\n",
      "Epoch 584/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 671245.5625 - val_loss: 684026.8750\n",
      "Epoch 585/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 669494.2500 - val_loss: 680367.7500\n",
      "Epoch 586/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 666367.6875 - val_loss: 679340.5000\n",
      "Epoch 587/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 663922.6875 - val_loss: 677418.5625\n",
      "Epoch 588/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 661265.8750 - val_loss: 675081.0625\n",
      "Epoch 589/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 659062.7500 - val_loss: 673316.3125\n",
      "Epoch 590/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 656873.0000 - val_loss: 672682.0000\n",
      "Epoch 591/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 654687.3125 - val_loss: 667357.2500\n",
      "Epoch 592/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 652346.5625 - val_loss: 665203.6875\n",
      "Epoch 593/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 649914.7500 - val_loss: 663120.0000\n",
      "Epoch 594/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 648375.3125 - val_loss: 662520.0625\n",
      "Epoch 595/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 645844.1250 - val_loss: 660738.8750\n",
      "Epoch 596/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 643836.0000 - val_loss: 657811.3750\n",
      "Epoch 597/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 641700.7500 - val_loss: 655208.6250\n",
      "Epoch 598/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 639970.3750 - val_loss: 651530.9375\n",
      "Epoch 599/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 637968.0000 - val_loss: 654591.2500\n",
      "Epoch 600/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 635533.8125 - val_loss: 650532.1875\n",
      "Epoch 601/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 634110.0625 - val_loss: 646865.9375\n",
      "Epoch 602/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 631388.6250 - val_loss: 646073.3125\n",
      "Epoch 603/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 630033.1250 - val_loss: 643291.1250\n",
      "Epoch 604/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 627524.2500 - val_loss: 642756.4375\n",
      "Epoch 605/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 625673.1250 - val_loss: 639491.8125\n",
      "Epoch 606/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 623912.7500 - val_loss: 640038.5000\n",
      "Epoch 607/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 621882.0000 - val_loss: 637824.6250\n",
      "Epoch 608/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 620327.7500 - val_loss: 633797.1875\n",
      "Epoch 609/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 618313.8125 - val_loss: 631074.8750\n",
      "Epoch 610/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 616625.8750 - val_loss: 630344.2500\n",
      "Epoch 611/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 614637.5625 - val_loss: 627720.1250\n",
      "Epoch 612/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 612972.5000 - val_loss: 625248.1875\n",
      "Epoch 613/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 611557.4375 - val_loss: 622770.3125\n",
      "Epoch 614/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 609727.7500 - val_loss: 622726.8750\n",
      "Epoch 615/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 608610.4375 - val_loss: 622415.0000\n",
      "Epoch 616/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 606292.8125 - val_loss: 619338.3125\n",
      "Epoch 617/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 604566.8750 - val_loss: 616983.6875\n",
      "Epoch 618/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 602802.3125 - val_loss: 615584.0000\n",
      "Epoch 619/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 601496.6250 - val_loss: 614677.2500\n",
      "Epoch 620/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 600430.4375 - val_loss: 608366.4375\n",
      "Epoch 621/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 598578.3750 - val_loss: 610039.6875\n",
      "Epoch 622/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 597031.1875 - val_loss: 607516.0000\n",
      "Epoch 623/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 595209.8750 - val_loss: 606239.4375\n",
      "Epoch 624/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 593534.2500 - val_loss: 605391.3750\n",
      "Epoch 625/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 592534.6250 - val_loss: 604108.5000\n",
      "Epoch 626/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 590894.4375 - val_loss: 602250.5625\n",
      "Epoch 627/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 588987.8750 - val_loss: 599776.1875\n",
      "Epoch 628/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 587470.5625 - val_loss: 598788.7500\n",
      "Epoch 629/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 586156.3750 - val_loss: 596752.0625\n",
      "Epoch 630/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 584596.6250 - val_loss: 594314.5625\n",
      "Epoch 631/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 582898.1250 - val_loss: 594630.0625\n",
      "Epoch 632/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 582094.3750 - val_loss: 592416.3750\n",
      "Epoch 633/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 580606.2500 - val_loss: 590990.2500\n",
      "Epoch 634/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 578984.1875 - val_loss: 589079.8125\n",
      "Epoch 635/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 577568.5000 - val_loss: 587539.2500\n",
      "Epoch 636/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 576218.1875 - val_loss: 587092.3125\n",
      "Epoch 637/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 574504.8125 - val_loss: 585289.0625\n",
      "Epoch 638/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 573331.6875 - val_loss: 584335.2500\n",
      "Epoch 639/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 572048.0000 - val_loss: 583624.4375\n",
      "Epoch 640/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 571102.0000 - val_loss: 584521.8750\n",
      "Epoch 641/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 569636.5625 - val_loss: 578326.5625\n",
      "Epoch 642/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 568247.9375 - val_loss: 579250.3125\n",
      "Epoch 643/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 566881.5625 - val_loss: 577602.0000\n",
      "Epoch 644/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 565904.1875 - val_loss: 574691.4375\n",
      "Epoch 645/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 564526.2500 - val_loss: 574782.9375\n",
      "Epoch 646/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 563105.6875 - val_loss: 574763.5625\n",
      "Epoch 647/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 562544.0625 - val_loss: 574734.4375\n",
      "Epoch 648/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 560831.6250 - val_loss: 572044.4375\n",
      "Epoch 649/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 559788.9375 - val_loss: 570492.1875\n",
      "Epoch 650/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 559942.8750 - val_loss: 569738.3125\n",
      "Epoch 651/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 557877.9375 - val_loss: 565205.3125\n",
      "Epoch 652/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 556511.1250 - val_loss: 565335.2500\n",
      "Epoch 653/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 555195.7500 - val_loss: 563899.7500\n",
      "Epoch 654/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 554128.0625 - val_loss: 564089.0625\n",
      "Epoch 655/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 552886.1250 - val_loss: 560801.8750\n",
      "Epoch 656/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 551566.9375 - val_loss: 561175.0000\n",
      "Epoch 657/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 550507.0000 - val_loss: 559171.0625\n",
      "Epoch 658/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 549588.6250 - val_loss: 559232.5000\n",
      "Epoch 659/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 548551.0625 - val_loss: 557201.2500\n",
      "Epoch 660/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 547508.8125 - val_loss: 559084.0625\n",
      "Epoch 661/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 546152.4375 - val_loss: 557897.4375\n",
      "Epoch 662/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 544868.6250 - val_loss: 555197.6875\n",
      "Epoch 663/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 544217.6250 - val_loss: 554630.9375\n",
      "Epoch 664/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 542864.6875 - val_loss: 553394.2500\n",
      "Epoch 665/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 542425.1250 - val_loss: 550893.9375\n",
      "Epoch 666/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 540876.2500 - val_loss: 550536.1250\n",
      "Epoch 667/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 540206.4375 - val_loss: 548750.7500\n",
      "Epoch 668/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 539233.9375 - val_loss: 552793.6250\n",
      "Epoch 669/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 538322.4375 - val_loss: 550257.5625\n",
      "Epoch 670/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 537232.0000 - val_loss: 549735.0625\n",
      "Epoch 671/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 536574.0000 - val_loss: 551507.0625\n",
      "Epoch 672/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 535412.7500 - val_loss: 548329.0625\n",
      "Epoch 673/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 534502.0000 - val_loss: 546187.5625\n",
      "Epoch 674/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 533723.5625 - val_loss: 546673.0625\n",
      "Epoch 675/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 532583.6875 - val_loss: 545133.6250\n",
      "Epoch 676/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 531839.0625 - val_loss: 543561.8750\n",
      "Epoch 677/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 531191.6250 - val_loss: 543166.0625\n",
      "Epoch 678/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 529888.2500 - val_loss: 541165.3750\n",
      "Epoch 679/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 529072.3750 - val_loss: 538825.1875\n",
      "Epoch 680/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 528277.3750 - val_loss: 537231.4375\n",
      "Epoch 681/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 527376.8125 - val_loss: 537084.1875\n",
      "Epoch 682/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 526360.7500 - val_loss: 537450.3125\n",
      "Epoch 683/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 525610.0000 - val_loss: 535545.8750\n",
      "Epoch 684/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 525081.0000 - val_loss: 535841.0000\n",
      "Epoch 685/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 524239.8750 - val_loss: 533676.6875\n",
      "Epoch 686/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 523082.9688 - val_loss: 532614.0000\n",
      "Epoch 687/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 522279.1875 - val_loss: 533052.1875\n",
      "Epoch 688/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 521432.8125 - val_loss: 530110.1250\n",
      "Epoch 689/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 520818.2500 - val_loss: 530474.8125\n",
      "Epoch 690/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 520016.2188 - val_loss: 529489.0000\n",
      "Epoch 691/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 518909.1562 - val_loss: 529887.8125\n",
      "Epoch 692/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 518960.1250 - val_loss: 531619.9375\n",
      "Epoch 693/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 517755.7188 - val_loss: 529597.8125\n",
      "Epoch 694/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 516698.2500 - val_loss: 528178.2500\n",
      "Epoch 695/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 516115.5000 - val_loss: 525707.0625\n",
      "Epoch 696/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 515094.7500 - val_loss: 525676.0625\n",
      "Epoch 697/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 514830.6250 - val_loss: 525023.5625\n",
      "Epoch 698/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 513736.5938 - val_loss: 524351.3750\n",
      "Epoch 699/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 513014.6250 - val_loss: 525028.0000\n",
      "Epoch 700/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 512727.7812 - val_loss: 527578.3125\n",
      "Epoch 701/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 512205.3750 - val_loss: 526044.0625\n",
      "Epoch 702/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 511175.2188 - val_loss: 524279.5625\n",
      "Epoch 703/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 510102.5312 - val_loss: 523880.9375\n",
      "Epoch 704/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 509674.3125 - val_loss: 523386.8750\n",
      "Epoch 705/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 509225.0000 - val_loss: 520850.1875\n",
      "Epoch 706/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 508304.5625 - val_loss: 520780.0938\n",
      "Epoch 707/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 507687.4062 - val_loss: 520815.6875\n",
      "Epoch 708/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 507013.6875 - val_loss: 521076.9062\n",
      "Epoch 709/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 506644.8125 - val_loss: 519861.2188\n",
      "Epoch 710/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 506582.4062 - val_loss: 522830.4688\n",
      "Epoch 711/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 505724.0000 - val_loss: 519317.3750\n",
      "Epoch 712/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 29ms/step - loss: 504597.8750 - val_loss: 516907.5312\n",
      "Epoch 713/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 505000.8750 - val_loss: 520081.7500\n",
      "Epoch 714/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 503205.0938 - val_loss: 515605.2812\n",
      "Epoch 715/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 502943.6250 - val_loss: 515089.0938\n",
      "Epoch 716/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 502073.9062 - val_loss: 514597.5625\n",
      "Epoch 717/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 502695.3438 - val_loss: 515555.6875\n",
      "Epoch 718/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 500811.0625 - val_loss: 514238.4062\n",
      "Epoch 719/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 500399.5625 - val_loss: 516327.2812\n",
      "Epoch 720/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 500083.3438 - val_loss: 513594.2812\n",
      "Epoch 721/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 500564.5938 - val_loss: 515183.9062\n",
      "Epoch 722/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 498597.3125 - val_loss: 512152.7188\n",
      "Epoch 723/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 498557.8750 - val_loss: 512430.8438\n",
      "Epoch 724/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 497426.5312 - val_loss: 511182.8438\n",
      "Epoch 725/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 496869.5312 - val_loss: 510662.5312\n",
      "Epoch 726/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 496564.6562 - val_loss: 513585.4688\n",
      "Epoch 727/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 495995.0625 - val_loss: 511826.5000\n",
      "Epoch 728/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 495140.2812 - val_loss: 509584.9375\n",
      "Epoch 729/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 494850.5625 - val_loss: 509874.5000\n",
      "Epoch 730/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 494468.5625 - val_loss: 509272.8125\n",
      "Epoch 731/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 493734.4688 - val_loss: 510208.5938\n",
      "Epoch 732/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 493841.3125 - val_loss: 510263.6875\n",
      "Epoch 733/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 492997.7500 - val_loss: 507621.6562\n",
      "Epoch 734/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 492909.0938 - val_loss: 508341.7188\n",
      "Epoch 735/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 491818.8438 - val_loss: 508186.0625\n",
      "Epoch 736/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 491046.0938 - val_loss: 505366.0312\n",
      "Epoch 737/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 491046.3125 - val_loss: 505493.5938\n",
      "Epoch 738/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 490515.1250 - val_loss: 504627.0000\n",
      "Epoch 739/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 489976.5625 - val_loss: 504002.0000\n",
      "Epoch 740/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 489656.5625 - val_loss: 504640.5312\n",
      "Epoch 741/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 489004.2812 - val_loss: 504652.2500\n",
      "Epoch 742/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 488708.7812 - val_loss: 505988.0938\n",
      "Epoch 743/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 488492.5000 - val_loss: 503347.4688\n",
      "Epoch 744/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 488084.7188 - val_loss: 504653.6562\n",
      "Epoch 745/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 487881.0312 - val_loss: 502185.1562\n",
      "Epoch 746/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 487029.2500 - val_loss: 502378.1875\n",
      "Epoch 747/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 486392.3750 - val_loss: 504355.1562\n",
      "Epoch 748/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 486121.6562 - val_loss: 501501.5938\n",
      "Epoch 749/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 485035.4375 - val_loss: 501653.0625\n",
      "Epoch 750/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 485032.2812 - val_loss: 502897.6250\n",
      "Epoch 751/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 484694.7812 - val_loss: 499631.1250\n",
      "Epoch 752/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 483898.0312 - val_loss: 500071.4062\n",
      "Epoch 753/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 483793.8750 - val_loss: 499127.1250\n",
      "Epoch 754/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 482800.9375 - val_loss: 499454.4688\n",
      "Epoch 755/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 482204.2188 - val_loss: 499287.6875\n",
      "Epoch 756/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 482217.1562 - val_loss: 498397.0000\n",
      "Epoch 757/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 481426.0938 - val_loss: 497666.2812\n",
      "Epoch 758/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 480982.3438 - val_loss: 498237.3750\n",
      "Epoch 759/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 480600.5938 - val_loss: 497345.9688\n",
      "Epoch 760/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 480248.7188 - val_loss: 496366.9688\n",
      "Epoch 761/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 479496.4375 - val_loss: 496182.0312\n",
      "Epoch 762/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 479093.3750 - val_loss: 497413.7812\n",
      "Epoch 763/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 478580.0625 - val_loss: 494296.0625\n",
      "Epoch 764/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 478056.7812 - val_loss: 497501.2188\n",
      "Epoch 765/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 477291.4062 - val_loss: 496144.0000\n",
      "Epoch 766/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 476882.7500 - val_loss: 493927.6875\n",
      "Epoch 767/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 476443.5625 - val_loss: 492750.3750\n",
      "Epoch 768/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 476168.3438 - val_loss: 491749.0000\n",
      "Epoch 769/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 475865.9688 - val_loss: 493263.6250\n",
      "Epoch 770/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 475009.7500 - val_loss: 492912.5312\n",
      "Epoch 771/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 474841.6562 - val_loss: 493506.7812\n",
      "Epoch 772/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 475686.4062 - val_loss: 488118.1562\n",
      "Epoch 773/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 473874.9062 - val_loss: 489557.1562\n",
      "Epoch 774/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 473457.6875 - val_loss: 490873.3750\n",
      "Epoch 775/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 473159.1875 - val_loss: 491019.9688\n",
      "Epoch 776/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 472427.6562 - val_loss: 490145.8438\n",
      "Epoch 777/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 472326.9062 - val_loss: 489219.2188\n",
      "Epoch 778/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 472189.6875 - val_loss: 488760.5000\n",
      "Epoch 779/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 471750.7500 - val_loss: 488104.3125\n",
      "Epoch 780/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 470927.7188 - val_loss: 487918.1562\n",
      "Epoch 781/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 470579.5000 - val_loss: 488988.1250\n",
      "Epoch 782/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 469942.9062 - val_loss: 487793.1875\n",
      "Epoch 783/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 469590.0312 - val_loss: 489170.1875\n",
      "Epoch 784/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 469819.0625 - val_loss: 488343.2812\n",
      "Epoch 785/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 469194.3438 - val_loss: 489488.9375\n",
      "Epoch 786/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 468333.2188 - val_loss: 487858.9375\n",
      "Epoch 787/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 468307.3438 - val_loss: 486993.5312\n",
      "Epoch 788/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 468451.2812 - val_loss: 486099.6562\n",
      "Epoch 789/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 468049.9688 - val_loss: 488864.7500\n",
      "Epoch 790/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 467177.0000 - val_loss: 485541.6562\n",
      "Epoch 791/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 466945.6875 - val_loss: 483280.5312\n",
      "Epoch 792/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 466405.5312 - val_loss: 485332.4688\n",
      "Epoch 793/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 466351.7188 - val_loss: 486635.3125\n",
      "Epoch 794/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 465991.0625 - val_loss: 485218.9375\n",
      "Epoch 795/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 465510.4688 - val_loss: 484936.5938\n",
      "Epoch 796/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 465729.4688 - val_loss: 483818.6250\n",
      "Epoch 797/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 464857.9062 - val_loss: 485438.8125\n",
      "Epoch 798/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 464572.0000 - val_loss: 483344.9688\n",
      "Epoch 799/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 464325.8125 - val_loss: 484175.7188\n",
      "Epoch 800/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 463749.6562 - val_loss: 483180.5312\n",
      "Epoch 801/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 463631.8750 - val_loss: 484445.5625\n",
      "Epoch 802/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 463711.1250 - val_loss: 484949.6562\n",
      "Epoch 803/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 462713.5312 - val_loss: 482172.8438\n",
      "Epoch 804/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 462716.0000 - val_loss: 481553.7500\n",
      "Epoch 805/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 462149.8125 - val_loss: 483215.4688\n",
      "Epoch 806/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 461862.3125 - val_loss: 481201.0312\n",
      "Epoch 807/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 461500.0625 - val_loss: 482201.4688\n",
      "Epoch 808/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 461071.8750 - val_loss: 482126.5312\n",
      "Epoch 809/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 461105.8125 - val_loss: 482986.2812\n",
      "Epoch 810/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 460381.8125 - val_loss: 481453.5938\n",
      "Epoch 811/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 460234.4062 - val_loss: 481435.8750\n",
      "Epoch 812/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 459929.5312 - val_loss: 481541.3750\n",
      "Epoch 813/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 459279.0000 - val_loss: 477763.8750\n",
      "Epoch 814/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 459440.5938 - val_loss: 479192.9688\n",
      "Epoch 815/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 459342.2500 - val_loss: 477379.9062\n",
      "Epoch 816/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 458498.2812 - val_loss: 480164.4062\n",
      "Epoch 817/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 458589.0000 - val_loss: 479540.0938\n",
      "Epoch 818/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 458199.9062 - val_loss: 480314.4375\n",
      "Epoch 819/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 457689.0000 - val_loss: 480871.3438\n",
      "Epoch 820/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 458416.7812 - val_loss: 478642.1250\n",
      "Epoch 821/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 457141.4062 - val_loss: 480634.1875\n",
      "Epoch 822/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 457076.7812 - val_loss: 481945.2500\n",
      "Epoch 823/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 456108.2188 - val_loss: 477616.7500\n",
      "Epoch 824/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 457024.5625 - val_loss: 476088.2812\n",
      "Epoch 825/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 455378.5625 - val_loss: 480391.4688\n",
      "Epoch 826/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 455852.0312 - val_loss: 479859.9688\n",
      "Epoch 827/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 455551.5625 - val_loss: 479635.5312\n",
      "Epoch 828/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 455759.9688 - val_loss: 476944.2812\n",
      "Epoch 829/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 454836.7812 - val_loss: 478347.0000\n",
      "Epoch 830/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 454232.4062 - val_loss: 475642.4375\n",
      "Epoch 831/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 454128.2500 - val_loss: 475269.8750\n",
      "Epoch 832/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 454146.3125 - val_loss: 476347.6562\n",
      "Epoch 833/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 453565.3438 - val_loss: 476739.5312\n",
      "Epoch 834/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 453537.3750 - val_loss: 475510.0938\n",
      "Epoch 835/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 453005.4375 - val_loss: 477975.5625\n",
      "Epoch 836/1000\n",
      "19/19 [==============================] - 1s 36ms/step - loss: 452635.6250 - val_loss: 477827.8125\n",
      "Epoch 837/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 452570.5938 - val_loss: 477352.4375\n",
      "Epoch 838/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 451946.2812 - val_loss: 476695.7188\n",
      "Epoch 839/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 451596.7500 - val_loss: 475013.1562\n",
      "Epoch 840/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 451316.5000 - val_loss: 474339.0938\n",
      "Epoch 841/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 451065.7188 - val_loss: 474884.5312\n",
      "Epoch 842/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 450767.7500 - val_loss: 475150.9062\n",
      "Epoch 843/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 450867.4375 - val_loss: 473999.6250\n",
      "Epoch 844/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 450357.8750 - val_loss: 475477.1250\n",
      "Epoch 845/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 449650.5000 - val_loss: 474364.1250\n",
      "Epoch 846/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 449275.9062 - val_loss: 473231.1250\n",
      "Epoch 847/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 449407.9688 - val_loss: 473798.3750\n",
      "Epoch 848/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 449023.0625 - val_loss: 472705.1562\n",
      "Epoch 849/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 449246.4062 - val_loss: 475257.9688\n",
      "Epoch 850/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 448554.0938 - val_loss: 475619.2188\n",
      "Epoch 851/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 447864.7500 - val_loss: 473424.0938\n",
      "Epoch 852/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 447765.4688 - val_loss: 474069.5938\n",
      "Epoch 853/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 448263.3125 - val_loss: 477679.4688\n",
      "Epoch 854/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 446831.3750 - val_loss: 474684.7500\n",
      "Epoch 855/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 446777.4688 - val_loss: 474417.1875\n",
      "Epoch 856/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 446719.9062 - val_loss: 473589.4375\n",
      "Epoch 857/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 446942.0312 - val_loss: 475320.3125\n",
      "Epoch 858/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 446229.0625 - val_loss: 475077.4375\n",
      "Epoch 859/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 445737.4375 - val_loss: 473301.3438\n",
      "Epoch 860/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 445624.2188 - val_loss: 471590.3750\n",
      "Epoch 861/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 445338.3438 - val_loss: 472620.0938\n",
      "Epoch 862/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 444952.4062 - val_loss: 472430.1562\n",
      "Epoch 863/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 444568.7188 - val_loss: 473557.1250\n",
      "Epoch 864/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 444579.9688 - val_loss: 474442.7188\n",
      "Epoch 865/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 444353.2500 - val_loss: 473079.9375\n",
      "Epoch 866/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 444377.1250 - val_loss: 474812.7812\n",
      "Epoch 867/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 443486.0938 - val_loss: 473786.7188\n",
      "Epoch 868/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 443457.2500 - val_loss: 470891.4375\n",
      "Epoch 869/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 442895.2188 - val_loss: 473221.0000\n",
      "Epoch 870/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 442759.2812 - val_loss: 471986.8750\n",
      "Epoch 871/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 442869.6875 - val_loss: 471152.0000\n",
      "Epoch 872/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 441940.2500 - val_loss: 473885.4375\n",
      "Epoch 873/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 441982.0312 - val_loss: 471645.2812\n",
      "Epoch 874/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 441239.5000 - val_loss: 472935.4062\n",
      "Epoch 875/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 440972.5625 - val_loss: 471980.3125\n",
      "Epoch 876/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 440959.7188 - val_loss: 470939.5312\n",
      "Epoch 877/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 440421.0625 - val_loss: 471201.3750\n",
      "Epoch 878/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 440378.7812 - val_loss: 471745.4062\n",
      "Epoch 879/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 440443.5000 - val_loss: 473800.6562\n",
      "Epoch 880/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 439708.1250 - val_loss: 471796.4062\n",
      "Epoch 881/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 439606.8125 - val_loss: 470693.2812\n",
      "Epoch 882/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 438936.7188 - val_loss: 469903.1875\n",
      "Epoch 883/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 438847.6562 - val_loss: 469600.0938\n",
      "Epoch 884/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 438970.1250 - val_loss: 468973.8750\n",
      "Epoch 885/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 438531.5000 - val_loss: 471284.4688\n",
      "Epoch 886/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 438232.9688 - val_loss: 469405.8750\n",
      "Epoch 887/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 437641.8125 - val_loss: 471445.6562\n",
      "Epoch 888/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 437089.6562 - val_loss: 469218.6250\n",
      "Epoch 889/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 436789.3438 - val_loss: 468922.5625\n",
      "Epoch 890/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 436890.3125 - val_loss: 468166.9688\n",
      "Epoch 891/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 436294.7812 - val_loss: 469652.9062\n",
      "Epoch 892/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 436422.6562 - val_loss: 468055.2812\n",
      "Epoch 893/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 436010.5000 - val_loss: 469529.8438\n",
      "Epoch 894/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 435915.1250 - val_loss: 468169.9688\n",
      "Epoch 895/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 435323.0000 - val_loss: 467170.4375\n",
      "Epoch 896/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 435030.9375 - val_loss: 467277.8750\n",
      "Epoch 897/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 434564.4375 - val_loss: 467660.7812\n",
      "Epoch 898/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 434205.4062 - val_loss: 467969.8438\n",
      "Epoch 899/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 434036.1250 - val_loss: 469687.9062\n",
      "Epoch 900/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 433854.8125 - val_loss: 469107.9062\n",
      "Epoch 901/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 433443.9688 - val_loss: 465988.4688\n",
      "Epoch 902/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 433718.7500 - val_loss: 464944.9375\n",
      "Epoch 903/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 432723.1250 - val_loss: 466493.2812\n",
      "Epoch 904/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 433066.0000 - val_loss: 467291.3125\n",
      "Epoch 905/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 432759.5938 - val_loss: 466517.9375\n",
      "Epoch 906/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 431970.9688 - val_loss: 465936.0938\n",
      "Epoch 907/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 431695.0312 - val_loss: 465686.2188\n",
      "Epoch 908/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 431632.7812 - val_loss: 466481.0312\n",
      "Epoch 909/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 431967.6250 - val_loss: 463912.0938\n",
      "Epoch 910/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 430976.8750 - val_loss: 465853.6562\n",
      "Epoch 911/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 430748.4375 - val_loss: 464689.7812\n",
      "Epoch 912/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 430495.1875 - val_loss: 465539.7500\n",
      "Epoch 913/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 430404.4062 - val_loss: 465026.1875\n",
      "Epoch 914/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 429815.5938 - val_loss: 464664.5000\n",
      "Epoch 915/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 430181.7812 - val_loss: 464460.6875\n",
      "Epoch 916/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 429696.4062 - val_loss: 466549.3438\n",
      "Epoch 917/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 429050.6250 - val_loss: 466042.0000\n",
      "Epoch 918/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 429190.3438 - val_loss: 464667.5312\n",
      "Epoch 919/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 428315.5312 - val_loss: 465778.4375\n",
      "Epoch 920/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 428553.2188 - val_loss: 466867.8125\n",
      "Epoch 921/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 427920.7188 - val_loss: 464311.6875\n",
      "Epoch 922/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 427437.4375 - val_loss: 465795.4688\n",
      "Epoch 923/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 427317.1562 - val_loss: 462977.0938\n",
      "Epoch 924/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 427882.1250 - val_loss: 461628.9062\n",
      "Epoch 925/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 427711.1875 - val_loss: 464817.7500\n",
      "Epoch 926/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 426799.2188 - val_loss: 462055.1875\n",
      "Epoch 927/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 426688.0625 - val_loss: 463400.3750\n",
      "Epoch 928/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 31ms/step - loss: 426287.0625 - val_loss: 463194.4062\n",
      "Epoch 929/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 426160.9688 - val_loss: 462408.8750\n",
      "Epoch 930/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 425483.2812 - val_loss: 462858.8750\n",
      "Epoch 931/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 425467.8750 - val_loss: 462465.7500\n",
      "Epoch 932/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 424793.0000 - val_loss: 464038.3125\n",
      "Epoch 933/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 424737.3750 - val_loss: 463329.0312\n",
      "Epoch 934/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 424438.4688 - val_loss: 462411.9062\n",
      "Epoch 935/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 424309.5000 - val_loss: 463010.1875\n",
      "Epoch 936/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 423772.8438 - val_loss: 461375.7188\n",
      "Epoch 937/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 424023.6562 - val_loss: 461643.3125\n",
      "Epoch 938/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 423162.3438 - val_loss: 460871.3438\n",
      "Epoch 939/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 423297.2500 - val_loss: 462677.2188\n",
      "Epoch 940/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 423423.2812 - val_loss: 459432.1562\n",
      "Epoch 941/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 422554.9375 - val_loss: 461635.2188\n",
      "Epoch 942/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 422862.1250 - val_loss: 462639.7188\n",
      "Epoch 943/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 421866.5312 - val_loss: 461418.0625\n",
      "Epoch 944/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 421484.0000 - val_loss: 461064.8125\n",
      "Epoch 945/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 421066.0938 - val_loss: 461372.3438\n",
      "Epoch 946/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 420873.2500 - val_loss: 462136.7500\n",
      "Epoch 947/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 421311.0625 - val_loss: 460782.1562\n",
      "Epoch 948/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 420584.3125 - val_loss: 460674.4375\n",
      "Epoch 949/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 420165.1250 - val_loss: 461375.1875\n",
      "Epoch 950/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 419755.0625 - val_loss: 460748.0312\n",
      "Epoch 951/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 419469.2500 - val_loss: 461159.7188\n",
      "Epoch 952/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 419320.3438 - val_loss: 460089.4688\n",
      "Epoch 953/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 418812.4688 - val_loss: 459762.5625\n",
      "Epoch 954/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 418777.0938 - val_loss: 459263.9375\n",
      "Epoch 955/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 418743.0000 - val_loss: 460270.0938\n",
      "Epoch 956/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 418427.3750 - val_loss: 460652.5625\n",
      "Epoch 957/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 417917.2188 - val_loss: 459928.1562\n",
      "Epoch 958/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 417564.5000 - val_loss: 460888.7500\n",
      "Epoch 959/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 417587.8125 - val_loss: 460859.0938\n",
      "Epoch 960/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 417329.6875 - val_loss: 459599.0312\n",
      "Epoch 961/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 416694.2812 - val_loss: 460138.5625\n",
      "Epoch 962/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 416457.0000 - val_loss: 460329.6875\n",
      "Epoch 963/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 416298.6562 - val_loss: 459418.3438\n",
      "Epoch 964/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 415908.3438 - val_loss: 459336.9688\n",
      "Epoch 965/1000\n",
      "19/19 [==============================] - 1s 33ms/step - loss: 415750.1250 - val_loss: 458647.5000\n",
      "Epoch 966/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 415733.5938 - val_loss: 455481.5000\n",
      "Epoch 967/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 414803.5625 - val_loss: 456652.5312\n",
      "Epoch 968/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 414805.0625 - val_loss: 458043.2188\n",
      "Epoch 969/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 414478.0000 - val_loss: 458244.3438\n",
      "Epoch 970/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 414143.0625 - val_loss: 457204.5625\n",
      "Epoch 971/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 414068.6875 - val_loss: 457067.4375\n",
      "Epoch 972/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 413602.5312 - val_loss: 456653.0000\n",
      "Epoch 973/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 413439.9375 - val_loss: 456132.9062\n",
      "Epoch 974/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 413171.2188 - val_loss: 457615.3438\n",
      "Epoch 975/1000\n",
      "19/19 [==============================] - 1s 34ms/step - loss: 413075.9375 - val_loss: 458803.6875\n",
      "Epoch 976/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 412494.8750 - val_loss: 457910.4062\n",
      "Epoch 977/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 412596.7188 - val_loss: 458867.0000\n",
      "Epoch 978/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 412285.3750 - val_loss: 458274.4375\n",
      "Epoch 979/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 411732.5625 - val_loss: 458275.3125\n",
      "Epoch 980/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 411814.1250 - val_loss: 458020.7812\n",
      "Epoch 981/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 411111.8750 - val_loss: 457135.5000\n",
      "Epoch 982/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 411005.4375 - val_loss: 457391.5000\n",
      "Epoch 983/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 411033.0625 - val_loss: 459765.8750\n",
      "Epoch 984/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 410224.3438 - val_loss: 458428.7812\n",
      "Epoch 985/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 410233.6875 - val_loss: 456041.0312\n",
      "Epoch 986/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 409432.9375 - val_loss: 457154.1875\n",
      "Epoch 987/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 409488.4688 - val_loss: 457181.7188\n",
      "Epoch 988/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 409173.5625 - val_loss: 455826.3750\n",
      "Epoch 989/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 408723.6562 - val_loss: 456614.0000\n",
      "Epoch 990/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 408642.6250 - val_loss: 456497.3750\n",
      "Epoch 991/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 408028.1250 - val_loss: 455717.4688\n",
      "Epoch 992/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 408069.0938 - val_loss: 455035.9062\n",
      "Epoch 993/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 408058.1875 - val_loss: 454384.2812\n",
      "Epoch 994/1000\n",
      "19/19 [==============================] - 1s 32ms/step - loss: 407062.7812 - val_loss: 455727.0000\n",
      "Epoch 995/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 406945.7812 - val_loss: 454957.3125\n",
      "Epoch 996/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 406327.7188 - val_loss: 456570.4062\n",
      "Epoch 997/1000\n",
      "19/19 [==============================] - 1s 29ms/step - loss: 406530.7500 - val_loss: 456479.7500\n",
      "Epoch 998/1000\n",
      "19/19 [==============================] - 1s 30ms/step - loss: 406103.3125 - val_loss: 455809.6562\n",
      "Epoch 999/1000\n",
      "19/19 [==============================] - 1s 31ms/step - loss: 405873.8750 - val_loss: 454855.9062\n",
      "Epoch 1000/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 1s 30ms/step - loss: 405681.3750 - val_loss: 453977.2500\n",
      "5/5 [==============================] - 0s 2ms/step - loss: 453977.2500\n",
      "Mean Squared Error on Test Data: 453977.25\n",
      "5/5 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "# Load the data\n",
    "day_Bike = pd.read_csv(r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv')  # Replace 'your_dataframe.csv' with the actual file path\n",
    "\n",
    "# Extract features and target\n",
    "features = day_Bike[['season', 'yr', 'mnth', 'holiday',\n",
    "                     'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']]\n",
    "target = day_Bike['cnt']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(1000, input_shape=(X_train.shape[1], X_train.shape[2])))\n",
    "model.add(Dense(1))\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs= 1000, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "96b90e5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-squared: -4.191555637839647\n"
     ]
    }
   ],
   "source": [
    "r_squared = r2_score(y_test, predictions)\n",
    "print(f'R-squared: {r_squared}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b20b0a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e57b8aeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 24467272.0000 - val_loss: 22320674.0000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24464028.0000 - val_loss: 22316782.0000\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24458676.0000 - val_loss: 22310096.0000\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24449562.0000 - val_loss: 22299156.0000\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24434920.0000 - val_loss: 22282288.0000\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24413180.0000 - val_loss: 22257834.0000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24383082.0000 - val_loss: 22225016.0000\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24342652.0000 - val_loss: 22182472.0000\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24293086.0000 - val_loss: 22130856.0000\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24233438.0000 - val_loss: 22069804.0000\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24162714.0000 - val_loss: 21999196.0000\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24082364.0000 - val_loss: 21920074.0000\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23993206.0000 - val_loss: 21833682.0000\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23898232.0000 - val_loss: 21738878.0000\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23790602.0000 - val_loss: 21637140.0000\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23676688.0000 - val_loss: 21529892.0000\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23563962.0000 - val_loss: 21415070.0000\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23431990.0000 - val_loss: 21295750.0000\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23301314.0000 - val_loss: 21169050.0000\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23169010.0000 - val_loss: 21039648.0000\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23025930.0000 - val_loss: 20904838.0000\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22874754.0000 - val_loss: 20765862.0000\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22724300.0000 - val_loss: 20620992.0000\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22581600.0000 - val_loss: 20474688.0000\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22410464.0000 - val_loss: 20325082.0000\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22257780.0000 - val_loss: 20170282.0000\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22067912.0000 - val_loss: 20012338.0000\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21903078.0000 - val_loss: 19849342.0000\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21726964.0000 - val_loss: 19683460.0000\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21555454.0000 - val_loss: 19515354.0000\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21360584.0000 - val_loss: 19343140.0000\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21177118.0000 - val_loss: 19169032.0000\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20974904.0000 - val_loss: 18991932.0000\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20768258.0000 - val_loss: 18809108.0000\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20598548.0000 - val_loss: 18628106.0000\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20401992.0000 - val_loss: 18445224.0000\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20178300.0000 - val_loss: 18255152.0000\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20027896.0000 - val_loss: 18068524.0000\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19779250.0000 - val_loss: 17875610.0000\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19587374.0000 - val_loss: 17678484.0000\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19361436.0000 - val_loss: 17482228.0000\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19181704.0000 - val_loss: 17281358.0000\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18918578.0000 - val_loss: 17079192.0000\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18708200.0000 - val_loss: 16874348.0000\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18512658.0000 - val_loss: 16670027.0000\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18282620.0000 - val_loss: 16465394.0000\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18063742.0000 - val_loss: 16260354.0000\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17834588.0000 - val_loss: 16051952.0000\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17588492.0000 - val_loss: 15842703.0000\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17360702.0000 - val_loss: 15633904.0000\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17179876.0000 - val_loss: 15424070.0000\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16955612.0000 - val_loss: 15215888.0000\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16695415.0000 - val_loss: 15006523.0000\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16461465.0000 - val_loss: 14796605.0000\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16268649.0000 - val_loss: 14587288.0000\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16015854.0000 - val_loss: 14377944.0000\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15854399.0000 - val_loss: 14168377.0000\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15561398.0000 - val_loss: 13960505.0000\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15330376.0000 - val_loss: 13749184.0000\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15071977.0000 - val_loss: 13534777.0000\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14930756.0000 - val_loss: 13323118.0000\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14650428.0000 - val_loss: 13111310.0000\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14419168.0000 - val_loss: 12897754.0000\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14196528.0000 - val_loss: 12686609.0000\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13992337.0000 - val_loss: 12475477.0000\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13741566.0000 - val_loss: 12266752.0000\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13456494.0000 - val_loss: 12052072.0000\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13271389.0000 - val_loss: 11843543.0000\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13038683.0000 - val_loss: 11639315.0000\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12806566.0000 - val_loss: 11434119.0000\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12571407.0000 - val_loss: 11227216.0000\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12363137.0000 - val_loss: 11026521.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12171372.0000 - val_loss: 10829826.0000\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11915284.0000 - val_loss: 10630779.0000\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11701490.0000 - val_loss: 10432488.0000\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11459537.0000 - val_loss: 10238959.0000\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11219359.0000 - val_loss: 10044369.0000\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11060786.0000 - val_loss: 9852251.0000\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10873525.0000 - val_loss: 9663016.0000\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10641802.0000 - val_loss: 9475124.0000\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10439655.0000 - val_loss: 9293956.0000\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10276775.0000 - val_loss: 9112184.0000\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10043309.0000 - val_loss: 8929961.0000\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9859275.0000 - val_loss: 8750366.0000\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9641743.0000 - val_loss: 8570515.0000\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9446298.0000 - val_loss: 8396651.0000\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9346790.0000 - val_loss: 8221084.5000\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 9107948.0000 - val_loss: 8052395.5000\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8855674.0000 - val_loss: 7882296.5000\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8716846.0000 - val_loss: 7719194.0000\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8482482.0000 - val_loss: 7556802.0000\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8270095.0000 - val_loss: 7400468.0000\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 8214748.0000 - val_loss: 7245424.5000\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7985888.5000 - val_loss: 7093150.0000\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7865431.0000 - val_loss: 6946357.5000\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7643768.0000 - val_loss: 6796916.5000\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7518387.5000 - val_loss: 6654395.0000\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7337932.5000 - val_loss: 6512359.5000\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7136800.5000 - val_loss: 6375066.5000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 7042861.0000 - val_loss: 6243223.0000\n",
      "5/5 [==============================] - 0s 999us/step - loss: 6243223.0000\n",
      "Mean Squared Error on Test Data: 6243223.0\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[3155.7095 1690.8014 2879.4338 2111.0427 3104.4258 3058.3638 1714.1097\n",
      " 2477.3508 3282.737  2933.7249 1959.9944 2486.67   2337.0227 2922.6858\n",
      " 1565.1835 1111.4144 1577.7719 3319.7544 2631.4602 1681.5844 3001.8677\n",
      " 3248.0754 2600.0886 1699.5477 2103.75   2715.1619 2318.8801 2875.4702\n",
      " 2194.9343 3099.339  1700.2828 3168.2678 2451.0508 2817.4402 2463.3606\n",
      " 2686.265  3343.0525 3150.2695 3068.388  1674.5947 2332.6782 2043.7404\n",
      " 3117.151  1953.84   2969.1033 3298.6575 2604.1182 2222.6921 2580.112\n",
      " 2223.535  2658.7139 1842.6971 1903.8856 2457.0588 2641.7405 3011.092\n",
      " 3141.5662 1729.359  1869.4846 3557.3833 2372.283  2929.954  2477.2488\n",
      " 2859.3362 3101.1584 2901.848  2896.119  2037.8328 2001.8081 2300.424\n",
      " 1824.3066 1740.2773 2706.949  2319.0251 2081.8242 2450.273  2833.3914\n",
      " 2837.9285 1254.0795 2510.6338 2928.153  1627.0709 3012.3877 3583.8013\n",
      " 2666.218  1906.714  2766.6213 2445.4128 2660.7979 2404.632  1626.9298\n",
      " 3070.5037 3153.1526 2526.2566 2815.4678 2146.586  2475.601  2039.5209\n",
      " 2321.5906 2778.8718 3078.9443 2187.721  2967.6926 1597.1581 2266.3523\n",
      " 3038.8887 2363.7085 2530.2239 3311.1233 1754.9337 2647.3381 3216.051\n",
      " 2616.9592 3186.6062 2807.013  2548.9934 2338.0144 2091.9583 2430.42\n",
      " 2367.341  2575.365  3183.0667 2192.5674 1414.4316 2625.388  2948.182\n",
      " 2639.8237 2536.6274 1855.0458 2585.8909 1874.6654 2714.987  2924.3577\n",
      " 3131.2495 2454.1152 2396.551  2735.382  2357.9036 2197.2278 2559.8013\n",
      " 2399.2866 1826.8097 1627.5256 2665.666  2694.161  2312.45   2188.1184]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "day_Bike = pd.read_csv(r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv')\n",
    "\n",
    "# Extract features and target\n",
    "features = day_Bike[['season', 'yr', 'mnth', 'holiday',\n",
    "                     'weekday', 'workingday', 'weathersit', 'temp', 'atemp', 'hum', 'windspeed']]\n",
    "\n",
    "\n",
    "target = day_Bike['cnt']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Using the Adam optimizer with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Adding early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extract values from predictions\n",
    "predicted_values = np.squeeze(predictions)\n",
    "\n",
    "# Now 'predicted_values' contains the predicted values from your LSTM model\n",
    "print(predicted_values)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ddb4d34f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>instant</th>\n",
       "      <th>dteday</th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2011-01-01</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.344167</td>\n",
       "      <td>0.363625</td>\n",
       "      <td>0.805833</td>\n",
       "      <td>0.160446</td>\n",
       "      <td>331</td>\n",
       "      <td>654</td>\n",
       "      <td>985</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2011-01-02</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.363478</td>\n",
       "      <td>0.353739</td>\n",
       "      <td>0.696087</td>\n",
       "      <td>0.248539</td>\n",
       "      <td>131</td>\n",
       "      <td>670</td>\n",
       "      <td>801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>2011-01-03</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.196364</td>\n",
       "      <td>0.189405</td>\n",
       "      <td>0.437273</td>\n",
       "      <td>0.248309</td>\n",
       "      <td>120</td>\n",
       "      <td>1229</td>\n",
       "      <td>1349</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2011-01-04</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.212122</td>\n",
       "      <td>0.590435</td>\n",
       "      <td>0.160296</td>\n",
       "      <td>108</td>\n",
       "      <td>1454</td>\n",
       "      <td>1562</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2011-01-05</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.226957</td>\n",
       "      <td>0.229270</td>\n",
       "      <td>0.436957</td>\n",
       "      <td>0.186900</td>\n",
       "      <td>82</td>\n",
       "      <td>1518</td>\n",
       "      <td>1600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>726</th>\n",
       "      <td>727</td>\n",
       "      <td>2012-12-27</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.254167</td>\n",
       "      <td>0.226642</td>\n",
       "      <td>0.652917</td>\n",
       "      <td>0.350133</td>\n",
       "      <td>247</td>\n",
       "      <td>1867</td>\n",
       "      <td>2114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>727</th>\n",
       "      <td>728</td>\n",
       "      <td>2012-12-28</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.255046</td>\n",
       "      <td>0.590000</td>\n",
       "      <td>0.155471</td>\n",
       "      <td>644</td>\n",
       "      <td>2451</td>\n",
       "      <td>3095</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>728</th>\n",
       "      <td>729</td>\n",
       "      <td>2012-12-29</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.253333</td>\n",
       "      <td>0.242400</td>\n",
       "      <td>0.752917</td>\n",
       "      <td>0.124383</td>\n",
       "      <td>159</td>\n",
       "      <td>1182</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>729</th>\n",
       "      <td>730</td>\n",
       "      <td>2012-12-30</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.255833</td>\n",
       "      <td>0.231700</td>\n",
       "      <td>0.483333</td>\n",
       "      <td>0.350754</td>\n",
       "      <td>364</td>\n",
       "      <td>1432</td>\n",
       "      <td>1796</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>730</th>\n",
       "      <td>731</td>\n",
       "      <td>2012-12-31</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.215833</td>\n",
       "      <td>0.223487</td>\n",
       "      <td>0.577500</td>\n",
       "      <td>0.154846</td>\n",
       "      <td>439</td>\n",
       "      <td>2290</td>\n",
       "      <td>2729</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>731 rows Ã— 16 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     instant      dteday  season  yr  mnth  holiday  weekday  workingday  \\\n",
       "0          1  2011-01-01       1   0     1        0        6           0   \n",
       "1          2  2011-01-02       1   0     1        0        0           0   \n",
       "2          3  2011-01-03       1   0     1        0        1           1   \n",
       "3          4  2011-01-04       1   0     1        0        2           1   \n",
       "4          5  2011-01-05       1   0     1        0        3           1   \n",
       "..       ...         ...     ...  ..   ...      ...      ...         ...   \n",
       "726      727  2012-12-27       1   1    12        0        4           1   \n",
       "727      728  2012-12-28       1   1    12        0        5           1   \n",
       "728      729  2012-12-29       1   1    12        0        6           0   \n",
       "729      730  2012-12-30       1   1    12        0        0           0   \n",
       "730      731  2012-12-31       1   1    12        0        1           1   \n",
       "\n",
       "     weathersit      temp     atemp       hum  windspeed  casual  registered  \\\n",
       "0             2  0.344167  0.363625  0.805833   0.160446     331         654   \n",
       "1             2  0.363478  0.353739  0.696087   0.248539     131         670   \n",
       "2             1  0.196364  0.189405  0.437273   0.248309     120        1229   \n",
       "3             1  0.200000  0.212122  0.590435   0.160296     108        1454   \n",
       "4             1  0.226957  0.229270  0.436957   0.186900      82        1518   \n",
       "..          ...       ...       ...       ...        ...     ...         ...   \n",
       "726           2  0.254167  0.226642  0.652917   0.350133     247        1867   \n",
       "727           2  0.253333  0.255046  0.590000   0.155471     644        2451   \n",
       "728           2  0.253333  0.242400  0.752917   0.124383     159        1182   \n",
       "729           1  0.255833  0.231700  0.483333   0.350754     364        1432   \n",
       "730           2  0.215833  0.223487  0.577500   0.154846     439        2290   \n",
       "\n",
       "      cnt  \n",
       "0     985  \n",
       "1     801  \n",
       "2    1349  \n",
       "3    1562  \n",
       "4    1600  \n",
       "..    ...  \n",
       "726  2114  \n",
       "727  3095  \n",
       "728  1341  \n",
       "729  1796  \n",
       "730  2729  \n",
       "\n",
       "[731 rows x 16 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "day_Bike"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f08938e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "2296.1843\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have new data in the same format as your training data\n",
    "# Replace 'new_data' with your actual new data\n",
    "new_data = pd.DataFrame({\n",
    "    'season': [1], 'yr': [1], 'mnth': [12], 'holiday': [0], 'weekday': [1],\n",
    "    'workingday': [1], 'weathersit': [1], 'temp': [0.215833], 'atemp': [0.223487],\n",
    "    'hum': [0.577500], 'windspeed': [0.154846]\n",
    "})\n",
    "\n",
    "# Normalize new features using the same scaler\n",
    "new_features_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "new_features_scaled = new_features_scaled.reshape((new_features_scaled.shape[0], 1, new_features_scaled.shape[1]))\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "new_predictions = model.predict(new_features_scaled)\n",
    "\n",
    "# Extract values from predictions\n",
    "predicted_cnt_values = np.squeeze(new_predictions)\n",
    "\n",
    "# Now 'predicted_cnt_values' contains the predicted \"cnt\" values for the new data\n",
    "print(predicted_cnt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd75f92c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4812bdad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "30884730",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 24467762.0000 - val_loss: 22321810.0000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24466298.0000 - val_loss: 22320080.0000\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24463940.0000 - val_loss: 22317108.0000\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24459982.0000 - val_loss: 22312194.0000\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24453668.0000 - val_loss: 22304768.0000\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24444448.0000 - val_loss: 22294196.0000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24431560.0000 - val_loss: 22279902.0000\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24414742.0000 - val_loss: 22260786.0000\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24393080.0000 - val_loss: 22236746.0000\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24365146.0000 - val_loss: 22207652.0000\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24331534.0000 - val_loss: 22171618.0000\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24290974.0000 - val_loss: 22129848.0000\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24245526.0000 - val_loss: 22082216.0000\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24190850.0000 - val_loss: 22026950.0000\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24131818.0000 - val_loss: 21965684.0000\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24067158.0000 - val_loss: 21900096.0000\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23994596.0000 - val_loss: 21828806.0000\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23915660.0000 - val_loss: 21750858.0000\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23833178.0000 - val_loss: 21667804.0000\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23741504.0000 - val_loss: 21579666.0000\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23648100.0000 - val_loss: 21487912.0000\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23547962.0000 - val_loss: 21390866.0000\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23445568.0000 - val_loss: 21288758.0000\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23334982.0000 - val_loss: 21183282.0000\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23218420.0000 - val_loss: 21075016.0000\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23108100.0000 - val_loss: 20961912.0000\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22985244.0000 - val_loss: 20844698.0000\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22866680.0000 - val_loss: 20726874.0000\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22737980.0000 - val_loss: 20604486.0000\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22606200.0000 - val_loss: 20479380.0000\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22469972.0000 - val_loss: 20353138.0000\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22338300.0000 - val_loss: 20224090.0000\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22206620.0000 - val_loss: 20092032.0000\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22063278.0000 - val_loss: 19957604.0000\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21919094.0000 - val_loss: 19822834.0000\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21784748.0000 - val_loss: 19682512.0000\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21608444.0000 - val_loss: 19539340.0000\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21486800.0000 - val_loss: 19395726.0000\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21317648.0000 - val_loss: 19247272.0000\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21168642.0000 - val_loss: 19098600.0000\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21004688.0000 - val_loss: 18945642.0000\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20846212.0000 - val_loss: 18795876.0000\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20692660.0000 - val_loss: 18639914.0000\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20517084.0000 - val_loss: 18484516.0000\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20337970.0000 - val_loss: 18325550.0000\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20186602.0000 - val_loss: 18165672.0000\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20002794.0000 - val_loss: 18007892.0000\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19847876.0000 - val_loss: 17845386.0000\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19658546.0000 - val_loss: 17683156.0000\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19492434.0000 - val_loss: 17518686.0000\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19339070.0000 - val_loss: 17353712.0000\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19131618.0000 - val_loss: 17187140.0000\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18959432.0000 - val_loss: 17018328.0000\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18806698.0000 - val_loss: 16850586.0000\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18644744.0000 - val_loss: 16684851.0000\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18423506.0000 - val_loss: 16514772.0000\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18265992.0000 - val_loss: 16343562.0000\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18082122.0000 - val_loss: 16174047.0000\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17909308.0000 - val_loss: 16006370.0000\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17693888.0000 - val_loss: 15831747.0000\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17539586.0000 - val_loss: 15658736.0000\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17347174.0000 - val_loss: 15487944.0000\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17175104.0000 - val_loss: 15318821.0000\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16985134.0000 - val_loss: 15145554.0000\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16804806.0000 - val_loss: 14977451.0000\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16600180.0000 - val_loss: 14803480.0000\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16426633.0000 - val_loss: 14632225.0000\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16223374.0000 - val_loss: 14459040.0000\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16074633.0000 - val_loss: 14287891.0000\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15850831.0000 - val_loss: 14116677.0000\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15696382.0000 - val_loss: 13946032.0000\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15501505.0000 - val_loss: 13775367.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15334984.0000 - val_loss: 13603713.0000\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15119979.0000 - val_loss: 13432336.0000\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14988155.0000 - val_loss: 13262702.0000\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14780712.0000 - val_loss: 13094179.0000\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14558063.0000 - val_loss: 12921453.0000\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14431348.0000 - val_loss: 12751699.0000\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14198552.0000 - val_loss: 12583598.0000\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14051325.0000 - val_loss: 12415134.0000\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13870531.0000 - val_loss: 12250749.0000\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13696363.0000 - val_loss: 12084685.0000\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13528270.0000 - val_loss: 11918743.0000\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13355381.0000 - val_loss: 11753503.0000\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13160884.0000 - val_loss: 11590165.0000\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13030467.0000 - val_loss: 11430161.0000\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12766012.0000 - val_loss: 11270835.0000\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12617867.0000 - val_loss: 11109069.0000\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12427428.0000 - val_loss: 10948233.0000\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12342532.0000 - val_loss: 10790493.0000\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12145992.0000 - val_loss: 10632492.0000\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11901229.0000 - val_loss: 10475631.0000\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11706379.0000 - val_loss: 10318646.0000\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11587500.0000 - val_loss: 10165716.0000\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11404445.0000 - val_loss: 10011514.0000\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11306806.0000 - val_loss: 9859839.0000\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11050194.0000 - val_loss: 9710525.0000\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10918139.0000 - val_loss: 9562058.0000\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10815537.0000 - val_loss: 9415678.0000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10592353.0000 - val_loss: 9270047.0000\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9270047.0000\n",
      "Mean Squared Error on Test Data: 9270047.0\n",
      "5/5 [==============================] - 0s 997us/step\n",
      "[2472.526   1557.8198  2082.3462  1273.6891  2315.1904  2305.0886\n",
      " 1459.0009  2187.7341  2494.75    2104.6416  1712.0148  2092.5332\n",
      " 1579.466   2514.8533  1414.8087   580.5741  1314.4698  2651.7954\n",
      " 1923.5465  1553.3903  2357.593   2442.342   2242.4     1314.4698\n",
      " 1557.8198  1784.4352  1514.0143  2220.191   2137.0305  2472.526\n",
      " 1117.0934  2082.3462  2147.2153  2347.5024  2051.8018  1809.7922\n",
      " 2547.125   2075.2075  1944.1423  1302.9447  1568.6667  1998.8549\n",
      " 2357.593    763.4603  2114.8337  1997.1014  1535.8116  1902.9387\n",
      " 1768.6747  1217.0286  1400.3058  1117.0934  1711.9784  1440.8241\n",
      " 1687.6425  2029.5228  2029.5228   702.69305  702.69305 2547.125\n",
      " 1902.9387  2157.3882  1763.4786  2075.2075  2167.5503  2252.5303\n",
      " 2066.2576   823.8089  1217.2788  1550.1246  1217.2788  1160.109\n",
      " 1805.2833  1763.4788  1945.7833  1470.0673  2420.1204  1794.872\n",
      " 1200.9348  1677.049   2661.8223  1314.4698  2704.0984  2272.766\n",
      " 2187.7341  1809.7922  1550.1492  1799.768   2187.7341  1805.2833\n",
      " 1200.9348  2262.6523  2704.0984  2189.7534  2756.3838  1756.236\n",
      " 1644.3387  1988.5695  1329.9861  1870.3588  2452.4082   883.64014\n",
      " 2062.0293  1217.2788  1314.4698  2567.2083  1901.3766  1711.9784\n",
      " 2399.9763  1359.1173  1687.6425  2651.7954  1698.202   2599.4722\n",
      " 2094.4363  1550.1492  1655.7518  2084.2178  1440.8241  1988.5695\n",
      " 2337.4055  1944.1423  1709.7358  1200.9348  1751.8408  2514.8533\n",
      " 1633.6885  1895.638   1514.0143  1440.7424  1001.55615 2039.7444\n",
      " 2514.8533  2567.2083  1687.6425  1763.4788  2147.2153  1863.1613\n",
      " 1709.7358  1590.2203  1720.31    1257.9811  1217.2788  1633.6885\n",
      " 2135.079   1677.049   1425.9691 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "day_Bike = pd.read_csv(r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv')\n",
    "\n",
    "# Extract features and target\n",
    "features = day_Bike[['yr', 'mnth', \n",
    "                     'holiday', 'weekday', 'workingday' ]]\n",
    "\n",
    "\n",
    "target = day_Bike['cnt']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Using the Adam optimizer with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Adding early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extract values from predictions\n",
    "predicted_values = np.squeeze(predictions)\n",
    "\n",
    "# Now 'predicted_values' contains the predicted values from your LSTM model\n",
    "print(predicted_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1f114bf6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 16ms/step\n",
      "2377.7556\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have new data in the same format as your training data\n",
    "# Replace 'new_data' with your actual new data\n",
    "new_data = pd.DataFrame({\n",
    "     'yr': [1], 'mnth': [12], 'holiday': [0], 'weekday': [1],\n",
    "    'workingday': [1]\n",
    "     \n",
    "})\n",
    "\n",
    "# Normalize new features using the same scaler\n",
    "new_features_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "new_features_scaled = new_features_scaled.reshape((new_features_scaled.shape[0], 1, new_features_scaled.shape[1]))\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "new_predictions = model.predict(new_features_scaled)\n",
    "\n",
    "# Extract values from predictions\n",
    "predicted_cnt_values = np.squeeze(new_predictions)\n",
    "\n",
    "# Now 'predicted_cnt_values' contains the predicted \"cnt\" values for the new data\n",
    "print(predicted_cnt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ff4d333",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d171ca73",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0b55796",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "19/19 [==============================] - 1s 12ms/step - loss: 24467660.0000 - val_loss: 22321592.0000\n",
      "Epoch 2/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24465768.0000 - val_loss: 22319430.0000\n",
      "Epoch 3/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24462826.0000 - val_loss: 22315992.0000\n",
      "Epoch 4/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24458076.0000 - val_loss: 22310554.0000\n",
      "Epoch 5/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24450946.0000 - val_loss: 22302468.0000\n",
      "Epoch 6/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24440240.0000 - val_loss: 22290950.0000\n",
      "Epoch 7/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24425508.0000 - val_loss: 22275096.0000\n",
      "Epoch 8/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24405666.0000 - val_loss: 22254546.0000\n",
      "Epoch 9/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24380010.0000 - val_loss: 22228390.0000\n",
      "Epoch 10/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24348308.0000 - val_loss: 22196402.0000\n",
      "Epoch 11/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24310146.0000 - val_loss: 22158484.0000\n",
      "Epoch 12/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24263954.0000 - val_loss: 22113858.0000\n",
      "Epoch 13/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24213046.0000 - val_loss: 22062578.0000\n",
      "Epoch 14/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24152654.0000 - val_loss: 22006344.0000\n",
      "Epoch 15/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24085284.0000 - val_loss: 21943790.0000\n",
      "Epoch 16/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 24018680.0000 - val_loss: 21875040.0000\n",
      "Epoch 17/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23936360.0000 - val_loss: 21800738.0000\n",
      "Epoch 18/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23856390.0000 - val_loss: 21722604.0000\n",
      "Epoch 19/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23765710.0000 - val_loss: 21640846.0000\n",
      "Epoch 20/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23677464.0000 - val_loss: 21554190.0000\n",
      "Epoch 21/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23574480.0000 - val_loss: 21461138.0000\n",
      "Epoch 22/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23477198.0000 - val_loss: 21366406.0000\n",
      "Epoch 23/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23373938.0000 - val_loss: 21267476.0000\n",
      "Epoch 24/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23255574.0000 - val_loss: 21164544.0000\n",
      "Epoch 25/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23145380.0000 - val_loss: 21059408.0000\n",
      "Epoch 26/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 23026728.0000 - val_loss: 20949370.0000\n",
      "Epoch 27/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22904662.0000 - val_loss: 20837240.0000\n",
      "Epoch 28/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22771762.0000 - val_loss: 20721280.0000\n",
      "Epoch 29/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22650778.0000 - val_loss: 20604502.0000\n",
      "Epoch 30/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22527172.0000 - val_loss: 20482384.0000\n",
      "Epoch 31/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22393352.0000 - val_loss: 20359464.0000\n",
      "Epoch 32/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22259248.0000 - val_loss: 20232198.0000\n",
      "Epoch 33/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 22114890.0000 - val_loss: 20103900.0000\n",
      "Epoch 34/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21963598.0000 - val_loss: 19969946.0000\n",
      "Epoch 35/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21819166.0000 - val_loss: 19834834.0000\n",
      "Epoch 36/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21678536.0000 - val_loss: 19697522.0000\n",
      "Epoch 37/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21514504.0000 - val_loss: 19557508.0000\n",
      "Epoch 38/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21370196.0000 - val_loss: 19414624.0000\n",
      "Epoch 39/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21223646.0000 - val_loss: 19271530.0000\n",
      "Epoch 40/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 21054674.0000 - val_loss: 19126986.0000\n",
      "Epoch 41/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20884494.0000 - val_loss: 18979320.0000\n",
      "Epoch 42/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20737538.0000 - val_loss: 18831302.0000\n",
      "Epoch 43/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20567880.0000 - val_loss: 18681946.0000\n",
      "Epoch 44/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20427950.0000 - val_loss: 18529958.0000\n",
      "Epoch 45/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20253134.0000 - val_loss: 18375126.0000\n",
      "Epoch 46/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 20059018.0000 - val_loss: 18221454.0000\n",
      "Epoch 47/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19885072.0000 - val_loss: 18063766.0000\n",
      "Epoch 48/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19715086.0000 - val_loss: 17908258.0000\n",
      "Epoch 49/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19576590.0000 - val_loss: 17753358.0000\n",
      "Epoch 50/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19366322.0000 - val_loss: 17592736.0000\n",
      "Epoch 51/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19190888.0000 - val_loss: 17433488.0000\n",
      "Epoch 52/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 19037860.0000 - val_loss: 17272190.0000\n",
      "Epoch 53/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18865514.0000 - val_loss: 17114778.0000\n",
      "Epoch 54/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18676850.0000 - val_loss: 16955398.0000\n",
      "Epoch 55/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18489116.0000 - val_loss: 16791318.0000\n",
      "Epoch 56/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18324924.0000 - val_loss: 16625971.0000\n",
      "Epoch 57/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 18138114.0000 - val_loss: 16464398.0000\n",
      "Epoch 58/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17998276.0000 - val_loss: 16300488.0000\n",
      "Epoch 59/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17784916.0000 - val_loss: 16134254.0000\n",
      "Epoch 60/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17629160.0000 - val_loss: 15970480.0000\n",
      "Epoch 61/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17432220.0000 - val_loss: 15803256.0000\n",
      "Epoch 62/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17235254.0000 - val_loss: 15635959.0000\n",
      "Epoch 63/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 17073600.0000 - val_loss: 15468412.0000\n",
      "Epoch 64/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16856662.0000 - val_loss: 15299619.0000\n",
      "Epoch 65/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16672843.0000 - val_loss: 15131817.0000\n",
      "Epoch 66/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16509805.0000 - val_loss: 14965692.0000\n",
      "Epoch 67/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16318096.0000 - val_loss: 14799391.0000\n",
      "Epoch 68/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 16147616.0000 - val_loss: 14635429.0000\n",
      "Epoch 69/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15966192.0000 - val_loss: 14469020.0000\n",
      "Epoch 70/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15798880.0000 - val_loss: 14303646.0000\n",
      "Epoch 71/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15613710.0000 - val_loss: 14137425.0000\n",
      "Epoch 72/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15418033.0000 - val_loss: 13973500.0000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 73/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15225824.0000 - val_loss: 13807346.0000\n",
      "Epoch 74/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 15050093.0000 - val_loss: 13640063.0000\n",
      "Epoch 75/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14864530.0000 - val_loss: 13476261.0000\n",
      "Epoch 76/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14727405.0000 - val_loss: 13312081.0000\n",
      "Epoch 77/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14507226.0000 - val_loss: 13148572.0000\n",
      "Epoch 78/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14344812.0000 - val_loss: 12986567.0000\n",
      "Epoch 79/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 14125026.0000 - val_loss: 12822010.0000\n",
      "Epoch 80/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13961361.0000 - val_loss: 12662732.0000\n",
      "Epoch 81/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13851931.0000 - val_loss: 12501198.0000\n",
      "Epoch 82/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13662672.0000 - val_loss: 12340620.0000\n",
      "Epoch 83/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13458738.0000 - val_loss: 12180306.0000\n",
      "Epoch 84/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13257754.0000 - val_loss: 12018621.0000\n",
      "Epoch 85/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 13131109.0000 - val_loss: 11859800.0000\n",
      "Epoch 86/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12926474.0000 - val_loss: 11701933.0000\n",
      "Epoch 87/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12728651.0000 - val_loss: 11545485.0000\n",
      "Epoch 88/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12554549.0000 - val_loss: 11391031.0000\n",
      "Epoch 89/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12401769.0000 - val_loss: 11234760.0000\n",
      "Epoch 90/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12201338.0000 - val_loss: 11081635.0000\n",
      "Epoch 91/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 12080565.0000 - val_loss: 10927686.0000\n",
      "Epoch 92/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11875082.0000 - val_loss: 10778365.0000\n",
      "Epoch 93/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11679914.0000 - val_loss: 10627758.0000\n",
      "Epoch 94/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11557702.0000 - val_loss: 10479036.0000\n",
      "Epoch 95/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11366604.0000 - val_loss: 10331196.0000\n",
      "Epoch 96/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11252674.0000 - val_loss: 10183238.0000\n",
      "Epoch 97/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 11068589.0000 - val_loss: 10038596.0000\n",
      "Epoch 98/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10892744.0000 - val_loss: 9895234.0000\n",
      "Epoch 99/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10803113.0000 - val_loss: 9753779.0000\n",
      "Epoch 100/100\n",
      "19/19 [==============================] - 0s 3ms/step - loss: 10639497.0000 - val_loss: 9612224.0000\n",
      "5/5 [==============================] - 0s 1ms/step - loss: 9612224.0000\n",
      "Mean Squared Error on Test Data: 9612224.0\n",
      "5/5 [==============================] - 0s 1ms/step\n",
      "[2038.9192  1097.5869  2062.091   1844.0277  2114.2136  2069.6023\n",
      " 1220.4161  1491.6165  2174.2302  2098.083   1287.3735  1593.0441\n",
      " 1850.2289  1725.5297  1072.2472  1242.244   1176.5437  2074.644\n",
      " 1900.2031  1104.42    1957.3247  2172.439   1582.782   1322.8228\n",
      " 1601.1848  2119.2808  1891.1886  1926.929   1186.1843  1972.4393\n",
      " 1491.1973  2400.8267  1487.4629  1749.3325  1587.2401  2068.73\n",
      " 2200.2507  2383.712   2403.2698  1308.71    1853.9442  1125.5068\n",
      " 2093.4766  2069.4548  2129.722   2634.6304  2199.1687  1431.3435\n",
      " 1989.6467  2021.8318  2403.1084  1657.8871  1222.5007  2106.5574\n",
      " 2115.3872  2263.1328  2415.4175  1857.3914  2011.2632  2451.5742\n",
      " 1611.2708  2045.9451  1865.9297  2035.5984  2246.0483  1931.8928\n",
      " 2102.934   2112.3853  1767.6326  1828.9458  1551.571   1499.0667\n",
      " 2099.1846  1670.861   1220.7397  2081.5881  1702.9717  2260.3708\n",
      "  886.25836 1971.3401  1613.7903  1233.7655  1665.455   2726.6624\n",
      " 1712.4513  1129.6072  2384.8767  1806.655   1706.3049  1736.3651\n",
      " 1338.4211  2120.8315  1832.7001  1542.5614  1391.747   1477.2003\n",
      " 1958.0024  1134.9266  2049.036   2119.7717  1965.5767  2242.0356\n",
      " 2180.8333  1282.5294  1994.5759  1818.0504  1615.0833  1971.6062\n",
      " 2283.9072  1357.1696  2121.7327  1952.6427  2084.2651  1964.9404\n",
      " 1964.5862  2131.4556  1794.3923  1105.8102  2076.1182  1536.8298\n",
      " 1467.6683  2544.3525  1568.5608  1078.8246  2042.0178  1756.0217\n",
      " 2158.6143  1831.1489  1335.7347  2261.3794  1787.0242  1899.4316\n",
      " 1727.6938  1933.3124  1894.7775  1770.259   1833.6272  1627.5386\n",
      " 1581.3413  2101.4526  1804.183   1519.2812  1320.5063  2188.4922\n",
      " 1791.5454  1737.7764  1805.0056 ]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "# Load the data\n",
    "day_Bike = pd.read_csv(r'C:\\Users\\jackf\\OneDrive\\Desktop\\Bike_Sharing\\UCI_Bike_Sharing\\data\\day.csv')\n",
    "\n",
    "# Extract features and target\n",
    "features = day_Bike[['season',  'weathersit', \n",
    "                     'temp', 'atemp', 'hum', 'windspeed']]\n",
    "\n",
    "\n",
    "target = day_Bike['cnt']\n",
    "\n",
    "# Normalize features\n",
    "scaler = MinMaxScaler()\n",
    "features_scaled = scaler.fit_transform(features)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(features_scaled, target.values, test_size=0.2, random_state=42)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "X_train = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test = X_test.reshape((X_test.shape[0], 1, X_test.shape[1]))\n",
    "\n",
    "# Build the LSTM model\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(X_train.shape[1], X_train.shape[2]), activation='relu'))\n",
    "model.add(Dropout(0.2))  # Adding dropout for regularization\n",
    "model.add(Dense(1))\n",
    "\n",
    "# Using the Adam optimizer with a lower learning rate\n",
    "optimizer = Adam(learning_rate=0.001)\n",
    "model.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Adding early stopping to prevent overfitting\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True)\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=100, batch_size=32, validation_data=(X_test, y_test), callbacks=[early_stopping])\n",
    "\n",
    "# Evaluate the model\n",
    "mse = model.evaluate(X_test, y_test)\n",
    "print(f'Mean Squared Error on Test Data: {mse}')\n",
    "\n",
    "# Make predictions\n",
    "predictions = model.predict(X_test)\n",
    "\n",
    "# Extract values from predictions\n",
    "predicted_values = np.squeeze(predictions)\n",
    "\n",
    "# Now 'predicted_values' contains the predicted values from your LSTM model\n",
    "print(predicted_values)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c099921",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/1 [==============================] - 0s 14ms/step\n",
      "1090.5117\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have new data in the same format as your training data\n",
    "# Replace 'new_data' with your actual new data\n",
    "new_data = pd.DataFrame({\n",
    "    'season': [1],  'weathersit': [1], 'temp': [0.215833], 'atemp': [0.223487],\n",
    "    'hum': [0.577500], 'windspeed': [0.154846]\n",
    "})\n",
    "\n",
    "# Normalize new features using the same scaler\n",
    "new_features_scaled = scaler.transform(new_data)\n",
    "\n",
    "# Reshape data for LSTM\n",
    "new_features_scaled = new_features_scaled.reshape((new_features_scaled.shape[0], 1, new_features_scaled.shape[1]))\n",
    "\n",
    "# Use the trained model to make predictions\n",
    "new_predictions = model.predict(new_features_scaled)\n",
    "\n",
    "# Extract values from predictions\n",
    "predicted_cnt_values = np.squeeze(new_predictions)\n",
    "\n",
    "# Now 'predicted_cnt_values' contains the predicted \"cnt\" values for the new data\n",
    "print(predicted_cnt_values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fb2decb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3edbbd89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want the value near 2729\n",
    "\n",
    "# both 2626.3992\n",
    "# without weather 2188.2783\n",
    "# just weather 1090.8662"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
