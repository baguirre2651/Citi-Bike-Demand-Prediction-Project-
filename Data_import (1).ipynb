{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fec3db7f",
   "metadata": {},
   "source": [
    "## Instructions for someone that is setting these files new on their computer."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e238efe8",
   "metadata": {},
   "source": [
    "For most part you will just run the cells. However, you need to do few things.\n",
    "\n",
    "\n",
    "1. One is to import the given files into a new folder on your Desktop called \"Final_project\". \n",
    "2. Once you make the folder, make another folder inside this folder named \"Data\".\n",
    "3. Use the current_directory code. People that are on mac, it will be different. However, for both cases you just copy the output.\n",
    "4. Now what were your output is at the end of do \"\\Data\".\n",
    "\n",
    " ==> For example: 'C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Final_project' ==> my output.\n",
    " ==> now do 'C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Final_project\\Data'. Adding data.\n",
    " \n",
    "5. Now set this new output to the variable, \"value_target_directory\". \n",
    "6. Run all the cells, it takes a little bit for them to run, as your downloading big files.\n",
    "7. If you get the output at the end from \"df\". You imported the data correctly.\n",
    "\n",
    "8. Please don't run this code more than once, otherwise you are download many files over and over again, so only run it once. \n",
    "9. If you run into any problems, you will need to delete the files from \"Data\". refollow the instructions from above.\n",
    "10. If you want an extra copy of data in dataframe, you can rename \"combined_data.csv\", to a different value so it has another version. For example, \"combined_data_1.csv\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cc6fb936",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9119f77b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "current_directory = os.getcwd()\n",
    "current_directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef3127d1",
   "metadata": {},
   "source": [
    "## Replace this value with whatever output you have."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4afb0438",
   "metadata": {},
   "outputs": [],
   "source": [
    "value_target_directory = r'C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data' ## replace value or same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c90bcf25",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2023 Q3 (July – September)\n",
      "2023 Q2 (April – June)\n",
      "2023 Q1 (January – March)\n",
      "2022 Q4 (October – December)\n",
      "2022 Q3 (July – September)\n",
      "2022 Q2 (April – June)\n",
      "2022 Q1 (January – March)\n",
      "2021 Q4 (October – December)\n",
      "2021 Q3 (July – September)\n",
      "2021 Q2 (April – June)\n",
      "2021 Q1 (January – March)\n",
      "2020 Q4 (October – December)\n",
      "2020 Q3 (July – September)\n",
      "2020 Q2 (April – June)\n",
      "2020 Q1 (January – March)\n",
      "2019 Q4 (October – December)\n",
      "2019 Q3 (July – September)\n",
      "2019 Q2 (April – June)\n",
      "2019 Q1 (January – March)\n",
      "2018 Q4 (October – December)\n",
      "2018 Q3 (July – September)\n",
      "2018 Q2 (April – June)\n",
      "2018 Q1 (January – March)\n",
      "2017 Q4 (October – December)\n",
      "2017 Q3 (July – September)\n",
      "2017 Q2 (April – June)\n",
      "2017 Q1 (January – March)\n",
      "2016 Q4 (October – December)\n",
      "2016 Q3 (Launch, July 7 – September)\n"
     ]
    }
   ],
   "source": [
    "# List of words\n",
    "words_list = [\n",
    "    \"2023 Q3 (July – September)\",\n",
    "    \"2023 Q2 (April – June)\",\n",
    "    \"2023 Q1 (January – March)\",\n",
    "    \"2022 Q4 (October – December)\",\n",
    "    \"2022 Q3 (July – September)\",\n",
    "    \"2022 Q2 (April – June)\",\n",
    "    \"2022 Q1 (January – March)\",\n",
    "    \"2021 Q4 (October – December)\",\n",
    "    \"2021 Q3 (July – September)\",\n",
    "    \"2021 Q2 (April – June)\",\n",
    "    \"2021 Q1 (January – March)\",\n",
    "    \"2020 Q4 (October – December)\",\n",
    "    \"2020 Q3 (July – September)\",\n",
    "    \"2020 Q2 (April – June)\",\n",
    "    \"2020 Q1 (January – March)\",\n",
    "    \"2019 Q4 (October – December)\",\n",
    "    \"2019 Q3 (July – September)\",\n",
    "    \"2019 Q2 (April – June)\",\n",
    "    \"2019 Q1 (January – March)\",\n",
    "    \"2018 Q4 (October – December)\",\n",
    "    \"2018 Q3 (July – September)\",\n",
    "    \"2018 Q2 (April – June)\",\n",
    "    \"2018 Q1 (January – March)\",\n",
    "    \"2017 Q4 (October – December)\",\n",
    "    \"2017 Q3 (July – September)\",\n",
    "    \"2017 Q2 (April – June)\",\n",
    "    \"2017 Q1 (January – March)\",\n",
    "    \"2016 Q4 (October – December)\",\n",
    "    \"2016 Q3 (Launch, July 7 – September)\"\n",
    "]\n",
    "\n",
    "# Print the list of words\n",
    "for word in words_list:\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "285353aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloaded 2023 Q3 (July – September).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2023 Q3 (July – September).zip\n",
      "Downloaded 2023 Q2 (April – June).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2023 Q2 (April – June).zip\n",
      "Downloaded 2023 Q1 (January – March).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2023 Q1 (January – March).zip\n",
      "Downloaded 2022 Q3 (July – September).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2022 Q3 (July – September).zip\n",
      "Downloaded 2022 Q2 (April – June).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2022 Q2 (April – June).zip\n",
      "Downloaded 2022 Q1 (January – March).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2022 Q1 (January – March).zip\n",
      "Downloaded 2021 Q3 (July – September).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2021 Q3 (July – September).zip\n",
      "Downloaded 2021 Q2 (April – June).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2021 Q2 (April – June).zip\n",
      "Downloaded 2021 Q1 (January – March).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2021 Q1 (January – March).zip\n",
      "Downloaded 2020 Q3 (July – September).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2020 Q3 (July – September).zip\n",
      "Downloaded 2020 Q2 (April – June).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2020 Q2 (April – June).zip\n",
      "Downloaded 2020 Q1 (January – March).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2020 Q1 (January – March).zip\n",
      "Downloaded 2019 Q4 (October – December).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2019 Q4 (October – December).zip\n",
      "Downloaded 2019 Q3 (July – September).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2019 Q3 (July – September).zip\n",
      "Downloaded 2019 Q2 (April – June).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2019 Q2 (April – June).zip\n",
      "Downloaded 2019 Q1 (January – March).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2019 Q1 (January – March).zip\n",
      "Downloaded 2018 Q4 (October – December).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2018 Q4 (October – December).zip\n",
      "Downloaded 2018 Q3 (July – September).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2018 Q3 (July – September).zip\n",
      "Downloaded 2018 Q2 (April – June).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2018 Q2 (April – June).zip\n",
      "Downloaded 2018 Q1 (January – March).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2018 Q1 (January – March).zip\n",
      "Downloaded 2017 Q4 (October – December).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2017 Q4 (October – December).zip\n",
      "Downloaded 2017 Q3 (July – September).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2017 Q3 (July – September).zip\n",
      "Downloaded 2017 Q2 (April – June).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2017 Q2 (April – June).zip\n",
      "Downloaded 2017 Q1 (January – March).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2017 Q1 (January – March).zip\n",
      "Downloaded 2016 Q4 (October – December).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2016 Q4 (October – December).zip\n",
      "Downloaded 2016 Q3 (Launch, July 7 – September).zip to C:\\\\Users\\\\jackf\\\\OneDrive\\\\Desktop\\\\Bike_Sharing\\Data\\2016 Q3 (Launch, July 7 – September).zip\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import os\n",
    "\n",
    "# Define the URL\n",
    "url = \"https://bikeshare.metro.net/about/data/\"\n",
    "\n",
    "# Set the target directory where you want to save the downloaded files\n",
    "target_directory = value_target_directory \n",
    "\n",
    "# Set a user-agent header to mimic a web browser\n",
    "headers = {\n",
    "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/58.0.3029.110 Safari/537.36\"\n",
    "}\n",
    "\n",
    "# Send an HTTP GET request to the URL with the user-agent header\n",
    "response = requests.get(url, headers=headers)\n",
    "\n",
    "# Check if the request was successful\n",
    "if response.status_code == 200:\n",
    "    # Parse the HTML content of the page\n",
    "    soup = BeautifulSoup(response.content, 'html.parser')\n",
    "\n",
    "    # Find all hyperlinks in the page\n",
    "    hyperlinks = soup.find_all(\"a\")\n",
    "\n",
    "    if hyperlinks:\n",
    "        for link in hyperlinks:\n",
    "            # Get the URL of the hyperlink\n",
    "            hyperlink = link.get(\"href\")\n",
    "\n",
    "            # Check if the hyperlink text matches one of the words you're interested in\n",
    "            for word in words_list:\n",
    "                if word in link.text:\n",
    "                    # Download the content associated with the hyperlink\n",
    "                    response = requests.get(hyperlink, headers=headers)\n",
    "\n",
    "                    # Check if the download was successful and save the content with the original file extension\n",
    "                    if response.status_code == 200:\n",
    "                        # Get the original file extension from the URL\n",
    "                        file_extension = os.path.splitext(hyperlink)[1]\n",
    "\n",
    "                        # Create the full path for the target file\n",
    "                        target_file = os.path.join(target_directory, f\"{word}{file_extension}\")\n",
    "\n",
    "                        with open(target_file, \"wb\") as file:\n",
    "                            file.write(response.content)\n",
    "                        print(f\"Downloaded {word}{file_extension} to {target_file}\")\n",
    "                    else:\n",
    "                        print(f\"Failed to download {word}. Status code:\", response.status_code)\n",
    "\n",
    "else:\n",
    "    print(\"Failed to retrieve the web page. Status code:\", response.status_code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cbdf1876",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackf\\AppData\\Local\\Temp\\ipykernel_4792\\207039690.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file, encoding='ISO-8859-1')  # Specify the encoding if needed\n",
      "C:\\Users\\jackf\\AppData\\Local\\Temp\\ipykernel_4792\\207039690.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file, encoding='ISO-8859-1')  # Specify the encoding if needed\n",
      "C:\\Users\\jackf\\AppData\\Local\\Temp\\ipykernel_4792\\207039690.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file, encoding='ISO-8859-1')  # Specify the encoding if needed\n",
      "C:\\Users\\jackf\\AppData\\Local\\Temp\\ipykernel_4792\\207039690.py:21: DtypeWarning: Columns (10) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file, encoding='ISO-8859-1')  # Specify the encoding if needed\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined data saved as 'combined_data.csv' in the same directory as the ZIP files\n"
     ]
    }
   ],
   "source": [
    "import zipfile\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# Directory where the ZIP files are located\n",
    "directory = value_target_directory \n",
    "\n",
    "\n",
    "# List all ZIP files in the directory\n",
    "zip_files = [os.path.join(directory, file) for file in os.listdir(directory) if file.endswith(\".zip\")]\n",
    "\n",
    "# Create an empty list to store DataFrames\n",
    "dataframes = []\n",
    "\n",
    "# Extract the ZIP files and combine data into one large CSV\n",
    "for zip_file in zip_files:\n",
    "    with zipfile.ZipFile(zip_file, 'r') as zip_ref:\n",
    "        for file_info in zip_ref.infolist():\n",
    "            if file_info.filename.endswith('.csv'):\n",
    "                with zip_ref.open(file_info.filename) as csv_file:\n",
    "                    df = pd.read_csv(csv_file, encoding='ISO-8859-1')  # Specify the encoding if needed\n",
    "                    dataframes.append(df)\n",
    "\n",
    "# Concatenate the DataFrames into one\n",
    "combined_data = pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "# Save the combined data to a single CSV file\n",
    "combined_data.to_csv(os.path.join(directory, \"combined_data.csv\"), index=False)\n",
    "print(\"Combined data saved as 'combined_data.csv' in the same directory as the ZIP files\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "74e97f36",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jackf\\AppData\\Local\\Temp\\ipykernel_4792\\2414314238.py:14: DtypeWarning: Columns (10,17,19,20,21,22,23,24) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  df = pd.read_csv(csv_file_path)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Directory where the combined_data.csv file is located\n",
    "directory = value_target_directory \n",
    "\n",
    "\n",
    "# File name\n",
    "file_name = \"combined_data.csv\"\n",
    "\n",
    "# Create the full path to the CSV file\n",
    "csv_file_path = os.path.join(directory, file_name)\n",
    "\n",
    "# Read the CSV file into a Pandas DataFrame\n",
    "df = pd.read_csv(csv_file_path)\n",
    "\n",
    "# Now, you can work with the DataFrame 'df' as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1ff00e22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>trip_id</th>\n",
       "      <th>duration</th>\n",
       "      <th>start_time</th>\n",
       "      <th>end_time</th>\n",
       "      <th>start_station_id</th>\n",
       "      <th>start_lat</th>\n",
       "      <th>start_lon</th>\n",
       "      <th>end_station_id</th>\n",
       "      <th>end_lat</th>\n",
       "      <th>end_lon</th>\n",
       "      <th>...</th>\n",
       "      <th>end_station</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>bike_type</th>\n",
       "      <th>3000</th>\n",
       "      <th>Virtual Station</th>\n",
       "      <th>7/7/2016</th>\n",
       "      <th>N/A</th>\n",
       "      <th>Active</th>\n",
       "      <th>start station name</th>\n",
       "      <th>end station name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1912818.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7/7/2016 4:17</td>\n",
       "      <td>7/7/2016 4:20</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>34.056610</td>\n",
       "      <td>-118.23721</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>34.056610</td>\n",
       "      <td>-118.23721</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1919661.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>7/7/2016 6:00</td>\n",
       "      <td>7/7/2016 6:33</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>34.056610</td>\n",
       "      <td>-118.23721</td>\n",
       "      <td>3014.0</td>\n",
       "      <td>34.056610</td>\n",
       "      <td>-118.23721</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1933383.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>7/7/2016 10:32</td>\n",
       "      <td>7/7/2016 10:37</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>34.052898</td>\n",
       "      <td>-118.24156</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>34.052898</td>\n",
       "      <td>-118.24156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1944197.0</td>\n",
       "      <td>181.0</td>\n",
       "      <td>7/7/2016 10:37</td>\n",
       "      <td>7/7/2016 13:38</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>34.052898</td>\n",
       "      <td>-118.24156</td>\n",
       "      <td>3016.0</td>\n",
       "      <td>34.052898</td>\n",
       "      <td>-118.24156</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1940317.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>7/7/2016 12:51</td>\n",
       "      <td>7/7/2016 12:58</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>34.049889</td>\n",
       "      <td>-118.25588</td>\n",
       "      <td>3032.0</td>\n",
       "      <td>34.049889</td>\n",
       "      <td>-118.25588</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     trip_id  duration      start_time        end_time  start_station_id  \\\n",
       "0  1912818.0       3.0   7/7/2016 4:17   7/7/2016 4:20            3014.0   \n",
       "1  1919661.0      33.0   7/7/2016 6:00   7/7/2016 6:33            3014.0   \n",
       "2  1933383.0       5.0  7/7/2016 10:32  7/7/2016 10:37            3016.0   \n",
       "3  1944197.0     181.0  7/7/2016 10:37  7/7/2016 13:38            3016.0   \n",
       "4  1940317.0       7.0  7/7/2016 12:51  7/7/2016 12:58            3032.0   \n",
       "\n",
       "   start_lat  start_lon  end_station_id    end_lat    end_lon  ...  \\\n",
       "0  34.056610 -118.23721          3014.0  34.056610 -118.23721  ...   \n",
       "1  34.056610 -118.23721          3014.0  34.056610 -118.23721  ...   \n",
       "2  34.052898 -118.24156          3016.0  34.052898 -118.24156  ...   \n",
       "3  34.052898 -118.24156          3016.0  34.052898 -118.24156  ...   \n",
       "4  34.049889 -118.25588          3032.0  34.049889 -118.25588  ...   \n",
       "\n",
       "  end_station  Unnamed: 0 bike_type 3000  Virtual Station  7/7/2016  N/A  \\\n",
       "0         NaN         NaN       NaN  NaN              NaN       NaN  NaN   \n",
       "1         NaN         NaN       NaN  NaN              NaN       NaN  NaN   \n",
       "2         NaN         NaN       NaN  NaN              NaN       NaN  NaN   \n",
       "3         NaN         NaN       NaN  NaN              NaN       NaN  NaN   \n",
       "4         NaN         NaN       NaN  NaN              NaN       NaN  NaN   \n",
       "\n",
       "  Active  start station name end station name  \n",
       "0    NaN                 NaN              NaN  \n",
       "1    NaN                 NaN              NaN  \n",
       "2    NaN                 NaN              NaN  \n",
       "3    NaN                 NaN              NaN  \n",
       "4    NaN                 NaN              NaN  \n",
       "\n",
       "[5 rows x 25 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5362b846",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
